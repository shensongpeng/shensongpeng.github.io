{"meta":{"title":"松松闲谈","subtitle":"","description":"记录一下学习旅程","author":"shensongpeng","url":"https://songsong.ink","root":"/"},"pages":[{"title":"","date":"2022-05-15T08:41:27.453Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"about/index.html","permalink":"https://songsong.ink/about/index.html","excerpt":"","text":"here is something about me"},{"title":"","date":"2022-05-15T08:41:27.449Z","updated":"2022-05-15T08:41:27.449Z","comments":true,"path":"404.html","permalink":"https://songsong.ink/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"我的分类","date":"2021-07-12T11:33:53.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"categories/index.html","permalink":"https://songsong.ink/categories/index.html","excerpt":"","text":""},{"title":"我的朋友们","date":"2022-05-15T08:41:27.453Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"friends/index.html","permalink":"https://songsong.ink/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"所有标签","date":"2021-07-12T11:35:00.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"tags/index.html","permalink":"https://songsong.ink/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"git proxy problem","slug":"git-proxy-problem","date":"2022-05-15T16:28:53.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2022/05/15/a61a3351e369.html","link":"","permalink":"https://songsong.ink/2022/05/15/a61a3351e369.html","excerpt":"","text":"一、在git克隆代码时遇到无法克隆问题问题详细提示如下： 12Cloning into &#x27;MUNIT-keras&#x27;...fatal: unable to access &#x27;https://github.com/shaoanlu/MUNIT-keras.git/&#x27;: OpenSSL SSL_connect: Connection was reset in connection to github.com:443 二、问题的缘由之前为git设置了代理，现在通过软路由全局进行代理，可能出现了冲突问题。 三、解决方案取消了之前为git设置的代理 四、相关的命令如下12345678910##查看git配置git config --global -l##取消代理设置git config --global --unset http.proxygit config --global --unset https.proxy## 备份一下之前配置代理的命令git config --global http.proxy http://127.0.0.1:1080git config --global https.proxy http://127.0.0.1:1080","categories":[{"name":"git","slug":"git","permalink":"https://songsong.ink/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://songsong.ink/tags/git/"}]},{"title":"spring源码阅读","slug":"spring源码阅读","date":"2022-02-07T18:07:50.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2022/02/07/d91a37f31693.html","link":"","permalink":"https://songsong.ink/2022/02/07/d91a37f31693.html","excerpt":"","text":"IOC容器1 类怎么注入到容器中成为一个Bean?类注入到容器中需要三步 1 配置类 2 加载上下文 3 getbean2 配置类的三种形式 通过xml 注解 javaconfigb. 加载spring上下文xml： new ClassPathXmlApplicationCOntext(“xml”)注解: new AnnotationConfigApplication(config.class) xml方式和注解形式的上下文都是读取后成为BeanDefine BeanFactory","categories":[],"tags":[]},{"title":"开放Oracle cloud 实例的端口","slug":"oracle-cloud-vm-open-port","date":"2021-12-21T21:37:10.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/12/21/35adf57486dd.html","link":"","permalink":"https://songsong.ink/2021/12/21/35adf57486dd.html","excerpt":"","text":"甲骨文实例开放端口 控制台开放安全组 ubuntu系统默认使用了 iptables防火墙iptables 防火墙开放端口 iptables -I INPUT -p tcp –dport 80 -j ACCEPT","categories":[{"name":"vps","slug":"vps","permalink":"https://songsong.ink/categories/vps/"}],"tags":[{"name":"vps","slug":"vps","permalink":"https://songsong.ink/tags/vps/"}]},{"title":"linux hash commond","slug":"linux-hash-commond","date":"2021-12-14T17:45:48.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/12/14/af17eafac893.html","link":"","permalink":"https://songsong.ink/2021/12/14/af17eafac893.html","excerpt":"","text":"1.linux系统下的hash指令说明：linux系统下会有一个hash表，当你刚开机时这个hash表为空，每当你执行过一条命令时，hash表会记录下这条命令的路径，就相当于缓存一样。第一次执行命令shell解释器默认的会从PATH路径下寻找该命令的路径，当你第二次使用该命令时，shell解释器首先会查看hash表，没有该命令才会去PATH路径下寻找。hash表的作用：大大提高命令的调用速率。 2 hash命令参数-l 显示hash表内容 -r 清除hash表 -d openssl 删除表中某一条（删除openssl） -t openssl 查看openssl命令路径（hash表中没有的话，可以调用which命令） -p /usr/bin/openssl aliesopenssl 往hash表中添加一条，执行aliesopenssl即执行openssl命令（起别名） 用途判断环境中是否存在某命令 check_program_installed() { hash $1 &gt; /dev/null 2&gt;&amp;1 if [ “$?” != “0” ]; then print “command $1 not found. is it installed?.” exit 1 fi} 查看服务的启动日志journalctl -u minio.service ubuntu 启动bbrecho net.core.default_qdisc=fq &gt;&gt; /etc/sysctl.confecho net.ipv4.tcp_congestion_control=bbr &gt;&gt; /etc/sysctl.conf sysctl -p sysctl net.ipv4.tcp_available_congestion_control 就开启了。 执行 lsmod | grep bbr ，以检测 BBR 是否开启。","categories":[{"name":"linux-commond","slug":"linux-commond","permalink":"https://songsong.ink/categories/linux-commond/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://songsong.ink/tags/linux/"},{"name":"commond-line","slug":"commond-line","permalink":"https://songsong.ink/tags/commond-line/"}]},{"title":"win10打印服务无法启动","slug":"win10打印服务无法启动","date":"2021-12-13T14:36:59.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/12/13/666267bebac1.html","link":"","permalink":"https://songsong.ink/2021/12/13/666267bebac1.html","excerpt":"","text":"cmd输入 net start spooler。 启动错误 1068依赖服务或组无法启动，cmd中输入以下命令：sc config spooler depend= rpcss 然后再重新启动print spooler服务就可以了。","categories":[{"name":"win10","slug":"win10","permalink":"https://songsong.ink/categories/win10/"}],"tags":[{"name":"打印服务","slug":"打印服务","permalink":"https://songsong.ink/tags/%E6%89%93%E5%8D%B0%E6%9C%8D%E5%8A%A1/"}]},{"title":"内存泄漏","slug":"内存泄漏","date":"2021-11-17T16:05:18.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/11/17/fe26308ea62e.html","link":"","permalink":"https://songsong.ink/2021/11/17/fe26308ea62e.html","excerpt":"","text":"内存泄漏的情况1、静态集合类，如HashMap、LinkedList等等。如果这些容器为静态的，那么它们的生命周期与程序一致，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。简单而言，长生命周期的对象持有短生命周期对象的引用，尽管短生命周期的对象不再使用，但是因为长生命周期对象持有它的引用而导致不能被回收。 2、各种连接，如数据库连接、网络连接和IO连接等。在对数据库进行操作的过程中，首先需要建立与数据库的连接，当不再使用时，需要调用close方法来释放与数据库的连接。只有连接被关闭后，垃圾回收器才会回收对应的对象。否则，如果在访问数据库的过程中，对Connection、Statement或ResultSet不显性地关闭，将会造成大量的对象无法被回收，从而引起内存泄漏。 3、变量不合理的作用域。一般而言，一个变量的定义的作用范围大于其使用范围，很有可能会造成内存泄漏。另一方面，如果没有及时地把对象设置为null，很有可能导致内存泄漏的发生。 4、内部类持有外部类，如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持有外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露。 5、改变哈希值，当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露6、内存泄漏的另一个常见来源是缓存，一旦你把对象引用放入到缓存中，他就很容易遗忘，对于这个问题，可以使用WeakHashMap代表缓存，此种Map的特点是，当除了自身有对key的引用外，此key没有其他引用那么此map会自动丢弃此值 7、 内存泄漏第三个常见来源是监听器和其他回调，如果客户端在你实现的API中注册回调，却没有显示的取消，那么就会积聚。需要确保回调立即被当作垃圾回收的最佳方法是只保存他的若引用，例如将他们保存成为WeakHashMap中的键。 内存泄漏的现象定位内存泄漏","categories":[{"name":"内存泄漏","slug":"内存泄漏","permalink":"https://songsong.ink/categories/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"}],"tags":[]},{"title":"缓存相关问题","slug":"缓存相关问题","date":"2021-11-17T15:52:23.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/11/17/c72f053f30ad.html","link":"","permalink":"https://songsong.ink/2021/11/17/c72f053f30ad.html","excerpt":"","text":"1、缓存会出现的问题1.1缓存穿透问题描述缓存穿透是指缓存和数据库都没有数据，而用户不断发起请求 解决方法 接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 1.2 缓存击穿问题描述缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方法 设置热点数据永远不过期。 加互斥锁，互斥锁参考代码如下：1.3 缓存雪崩问题描述缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方法 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。 设置热点数据永远不过期。","categories":[{"name":"cache","slug":"cache","permalink":"https://songsong.ink/categories/cache/"}],"tags":[{"name":"cache","slug":"cache","permalink":"https://songsong.ink/tags/cache/"}]},{"title":"RPC的概念以及优缺点","slug":"RPC的概念以及优缺点","date":"2021-11-16T22:09:48.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/11/16/6498daf82f70.html","link":"","permalink":"https://songsong.ink/2021/11/16/6498daf82f70.html","excerpt":"","text":"RPC的概念RPC(远程过程调用)可以分为两部分：远程过程以及过程调用。远程过程是指每台机器上提供的服务，过程调用就是对远程过程调用以及数据传输。 RPC的优点RPC带来的优势其实就是分布式架构带来的优势。在RPC的支持下，可以实现模块的分布式部署，可以实现更好的维护性，扩展性以及协同式开发。 RPC带来的问题RPC的出现为构建分布式架构带来了便利，但是分布式系统本身的问题也被暴漏了下来。存在的问题如下： 通信延迟 地址空间隔离 局部故障 并发问题 1、通信延迟跨机器、网络出现的通信延迟的概率一定比同一台机器的进程间通信大。编解码也会带来性能损耗。而且网络通信也是不可靠的会出现乱序、错误、丢数据等问题。 2、地址空间隔离内存地址在一台机器上才有效 3、局部故障故障的发现和通知需要引入新的组件，故障的类型判断也会变得复杂，比如是网络链路故障还是机器故障，继而会存在数据不一致问题，故障节点和正常节点会出现数据不一致问题。 4、并发问题","categories":[{"name":"RPC","slug":"RPC","permalink":"https://songsong.ink/categories/RPC/"}],"tags":[]},{"title":"零拷贝","slug":"零拷贝","date":"2021-11-03T15:11:03.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/11/03/4104be24b2f4.html","link":"","permalink":"https://songsong.ink/2021/11/03/4104be24b2f4.html","excerpt":"","text":"什么是零拷贝零拷贝（Zero-copy）：指计算机执行操作时，cpu不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省CPU周期和内存带宽。 好处： 可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率。 零拷贝技术减少了用户进程地址空间和内核空间之间因为上下文切换带来的开销 Linux IO流程 DMA拷贝：通过DMA方式将文件从硬盘拷贝到内核缓冲区域 CPU拷贝：从内核缓冲区拷贝到用户用户空间缓冲区 读取一个文件然后通过Socket发送的流程 File.read(fileDesc,buf,len); Socket.send(socket,buf,len); 在上述过程中经历了四次拷贝：2次cpucopy，2次dma copy，4次上下文切换 怎么实现零拷贝零拷贝实际上就是减少IO流程中不必要的拷贝，需要操作系统的支持。通过直接将ReadBUfferkao拷贝到内核的SocketBuffer这样减少了一次cpu拷贝和两次上下文切换。 Java零拷贝的使用1 内存映射（mmap）将内核缓冲区映射到用户缓冲区，通过虚拟内存器实现，（存在时空开销所以不适合小文件）。Java通过MappedByteBUffer实现。cpu拷贝次数一次，dma拷贝次数不变。上下文切换四次 12345File file = new File(&quot;data.zip&quot;);RandomAccessFile rad = new RandomAccessFile(file,&quot;rw&quot;);FileChannel filechannel = raf.getChannel();MappedByteBuffer buffer = filechannel.map(FileChannel.MapMode.READ_ONLY,0,filechannel.size()); 3 JavaNIO FileChannel.transferToLinux2.1 提供了sendfile系统调用。可以实现内核读缓冲到socket缓冲的拷贝。一次cpu拷贝和两次DMA拷贝。两次上下文切换。 123456File file = new File(&quot;test.zip&quot;); RandomAccessFile raf = new RandomAccessFile(file, &quot;rw&quot;); FileChannel fileChannel = raf.getChannel(); SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(&quot;&quot;, 1234)); // 直接使用了transferTo()进行通道间的数据传输 fileChannel.transferTo(0, fileChannel.size(), socketChannel); Netty中的零拷贝哪里用到了零拷贝 kafka Netty RocketMQ Nginx Apache","categories":[{"name":"面试题","slug":"面试题","permalink":"https://songsong.ink/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"零拷贝","slug":"零拷贝","permalink":"https://songsong.ink/tags/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"}]},{"title":"linux挂载硬盘","slug":"linux挂载硬盘","date":"2021-11-02T14:16:00.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/11/02/7a593bbc05f0.html","link":"","permalink":"https://songsong.ink/2021/11/02/7a593bbc05f0.html","excerpt":"","text":"硬盘情况硬盘为无分区表的空白硬盘 步骤 fdisk -l 查看所有硬盘信息找到要挂载的硬盘（我要挂载的是/dev/sdb） fdisk /dev/sdb 输入g 常见GPT分区表 在输入n创建分区 mke2fs -t ext4 /dev/sdb1 将该分区的文件系统设置为ext4 parted -l 查看分区的文件系统确认设置成功 修改 /etc/fstab 添加要挂载的设备 和挂载点 mount -a 让上一步的修改立即生效","categories":[],"tags":[]},{"title":"rabbitmq记录","slug":"rabbitmq记录","date":"2021-10-02T23:34:01.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/10/02/8b32a579046d.html","link":"","permalink":"https://songsong.ink/2021/10/02/8b32a579046d.html","excerpt":"","text":"12### 添加用户rabbitmqctl add_user admin 111111 1rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 1rabbitmqctl set_user_tags admin administrator","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://songsong.ink/categories/rabbitmq/"}],"tags":[]},{"title":"面经记录","slug":"面经记录","date":"2021-09-27T15:33:12.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/09/27/cf616068382c.html","link":"","permalink":"https://songsong.ink/2021/09/27/cf616068382c.html","excerpt":"","text":"2021/9/27 小米 上来自我接受问项目遇到哪些难点 动态代理了解吗 static了解吗（回答可以修饰类 、方法和变量） 内部类有哪些（回到静态内部类，普通内部类，还有别的吗？你用过new Thead(new Runable() {})）引导我回到匿名内部类 异常有分类 运行时异常有哪些举例 ERROR可以被捕获吗 序列化反序列化了解吗？有哪些格式，什么时候会有用到系列化 ==和equals区别，基本数据类型能用equals吗？ 集合类有哪些，我把list和map，set都说了 说说map的put()方法步骤 你没提到map的扩容，说一说map的扩容机制","categories":[],"tags":[]},{"title":"面试常考问题总结","slug":"网络常考问题总结","date":"2021-09-25T22:40:11.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/09/25/82c441ab4d2c.html","link":"","permalink":"https://songsong.ink/2021/09/25/82c441ab4d2c.html","excerpt":"","text":"计算机网络面试题 对TCP协议的了解 TCP的特性以及为什么是可靠的？ 三次握手？为什么要做三次握手？ 三次握手说一下，ACK为啥加一。 time_wait状态知道不，说一下 HTTP请求报头，状态码 ios模型七层是什么，为什么分层。 TCP和UDP有什么区别？9 TCP怎么三次握手的？ 说下TCP断开连接的过程。 TCP的可靠是怎么保证的 三次握手、四次挥手、timewait意义 http状态吗 http报头有什么 传输视频用什么协议、传输文件用什么协议 10亿的数据如何找前10大的 TCP流量控制怎么实现 TCP建立链接后，网线突然拔掉，在插上，链接还在不在 TCP保活定时器应用层能知道吗 TIME_WAIT会不会占用端口号？TIME_WAIT占用大量端口号，客户端链接不上服务器，怎么解决？ Udp如何实现可靠性传输 遥控器控制电视是用tcp还是udp syn攻击解决方法（回答了一种） 四次挥手 timewait没有会发生什么（提示下回答） epoll 两种模式 边沿触发和水平触发（提示下回答出来） 虚拟内存 交换区 set和无序的set谁的效率高为什么 HTTP的了解 post和get的区别 HTTP详细的（不会，跳过） 6.浏览器输入www.maoyan.com发生了什么？ http长链接与短连接？长链接一直不断开会出现什么问题？怎么解决这个问题？ 长链接实现原理？ http中GET和POST请求的方式？ http状态码含义，500和502的区别？401？ ARP协议？ http中的一些请求方法。 8、Time_wait 状态的作用 三次握手解决了什么问题 两台主机能同时相互进行三次握手连接嘛 ARP协议 .为什么有了ip地址还要mac地址 Tcp有可能被劫持吗？ tcp传输过程中信息会泄露吗？ HTTPS怎么保证安全的 查看tcp状态用哪个命令 把这些状态统计起来用哪个命令（比如time_wait状态有几个） 粘包问题 说一下管道，进程间的五种通信方式，三种线程同步方式 为什么用无名管道不用有名管道 除了管道，具体说一下其他方式 .一般网络上的视频传输用的是什么协议 微信支付中客户端发起一笔支付用tcp还是udp HTTP协议常见的状态码 对称加密和非对称加密的区别 数字签名 tcp拥塞控制知道吗？讲一下拥塞控制 慢启动中的起始值是1，单位是什么？ tcp报文头部有哪些信息，怎么知道自己可以发送多少数据给对方？ socket编程里象征三次握手的地方在哪儿？TCP三次握手四次挥手的状态，如果没有TIME_WAIT状态会怎样，time-wait状态如果很多，怎么避免？ udp发送的数据一定是完整的嘛？ 为什么分层？（1）多层之间相互独立，灵活性好（2）结构上可分割开来，易于实现和维护（3）促进标准化工作 问我怎么获取ip地址，我给他讲了从应用层到各层的数据段封装。他说不是，然后让我用电脑打开cmd 输入ipconfig /all 看一下DHCP服务器问我DHCP是干啥的？我说不清楚，然后他给我讲了5分的DHCP原理 问了下进程通讯及目的，进程间内存隔离。 fork3次之后创建几个进程 linux两台主机之间拷贝数据命令 三次握手的过程？每一次都携带什么数据？为什么要给确认报文段中的ack的值加1，为什么不是2,3,4？（1）客户端请求建立连接，发送序列号（2）服务器确认连接，发送确认报文，并发送自己的序列号（3）客户端发送确认报文如果是在建立连接的过程中，那么这仅仅是一个规定，三次握手的协议就是如此说明的。在数据收发的过程中，确认号也表示了在次字节之前的数据已经收到的到确认，可以放心发送后边的数据，加一可以确定下一次发送应该其实的位置。 四次挥手最后主动断开方为什么要等待2MSL？TIME_WAIT状态是什么?（1）保证安全的断开连接，假设被动断开方第一次发送的断开请求报文在网络滞留了，收不到确认又重新发了一次，第二次收到了确认则连接断开，如果此时滞留的报文又到达了，此时主动断开方有可能已经重新建立的tcp连接，就会收到一个错误的报文（2）保证迟到的报文被丢弃 管道是半双工、socket是全双工 TCP和UDP的区别？如何处理TCP粘包问题？Tcp是面向连接的可靠的流式服务Udp是无连接的不可靠的数据报服务粘包问题的解决方法：（1） 暴力解决，每次需要发数据时再建立tcp连接，发送结束就断开连接（2） 定常数据结构，如果规定每次发送的数据报长度是一定的，那么接收方每次读取固定长读的报文即可（3） 不定长数据结构：多数情况我们使用的不是定长的数据结构，第一种方法可以规定一个特殊的符号作为结束符，每当遇到这个结束符才认为该报文接收结束，但是该方法只适用于字符数据，因 为对其他二进制数据无法确定是结束符还是要发送的数据第二种方法是，在固定的偏移位置写入报文的长度，接收方每次读取先获取到报文的长度，再接收该长度大小的报文即可 HTTP协议的报头是什么？请求方法？Http协议的报头是用来区分报文的类型，比如客户端发送一个请求报文，那么该报文是请求报文就要在报头中说明，是响应报文也要在报头中说明。Get、Post time_wait的意义，2 MLS指的是什么 HTTP协议头部的TTL字段代表什么？代表报文的最大跳数（最长生存时间），主要是为了防止报文段在网络中一直循环的进行传输所设置的，当达到最大跳数后该报文段会被自动丢弃。 操作系统 进程间通信 线程间通信， 线程间的同步方式具体说 说下共享内存 ，有两个进程，连接同一共享内存，这两个进程映射到共享内存上的虚拟地址是相同的吗？ 两个进程之间通过共享内存共享一段内存地址空间，这个是怎么实现的？ 共享内存解决互斥 进程线程的资源分配的区别 select和epoll吗？有什么区别？ 怎样解决线程互斥 虚拟空间地址大小用户态和内核态 系统调用从用户态到内核态的过程 epoll的ET、LT模式 简短的说下 内存泄漏，怎么解决？ 用户态内核态，切换过程 如果很多个用户同时用了一个系统调用，会发生什么情况？怎么解决？ Linux2.6版本后内核的抢占式，是依据什么可以进行抢占的 内存对齐，内存对齐是编译器还是操作系统实现的？为什么要有内存对齐？ 分页管理和分段管理的区别 软链接和硬链接的区别 udp发送的数据报在网络层丢失了怎么办？应用层会不会知道这个包丢失了？udp知不知道 连续多次malloc和free之后是否能直接使用内存（不懂） 僵尸进程的概念、处理方法？通过信号调用wait函数可能出现的问题？ 死锁 协程比线程有哪些优势 .两个进程之间使用管道会启动新进程吗 管道是怎么实现的 多进程和多线程区别？微信底层用的是多进程，你怎么看？（多进程相比多线程的优势）， select,poll,epoll的区别。 代码里面从一个文件读内容，操作系统都做了什么 linux命令 文件夹按时间排序显示的命令（没答出来），那ls -t中-t参数是什么意思 查看进程的命令（回答的ps -ef），-ef所表示的意思是什么 用过head命令吗 linux文件合并，进程状态查询，cpu内存使用查询，磁盘内存查询。 如何在Linux下查看磁盘空间？ 如何查看端口有没有监听？ 查看网络状态的命令 liunx命令，查看进程，查看负载均衡 介绍管道，项目中用的是什么管道，项目中怎么用的管道 Linux中对文件和进程等相关操作的命令。 Linux 查看系统IO的命令 建立软链接的命令 修改文件的读写权限用到的命令，这个命令有哪些参数？ 统计文件有多少行、多少字节用什么命令？ 查找文件里字符串的命令？ ps的参数 了解脚本，awk sed 如何查看tcp状态，用什么命令？查看进程的命令，查看负载均衡的命令，linux脚本里如何获取文件的某一行某一列数据 如何查看tcp的状态 netstat 如何查看共享内存 ipcs Tcp查看状态用什么命令，具体的参数，会出现什么状态？TIME_WAIT和CLOSE_WAIT有什么区别？ ttl 缺页中断 strcpy函数原型和实现 内存泄漏了怎么办？有哪些内存泄漏？内存泄漏的检测工具？ 布隆过滤器 read和fread的区别，哪个效率高 查看内存运行状态命令（一个八核的系统，如何查看所有内存运行状态） .Linux下操作指令执行过程 .recv函数返回值的意义 查看共享内存命令 pwd命令怎么实现的 top和ps命令 在linux下，程序出现了死循环，会产生什么现象，除了jdb调试，还有其他什么方法可以查看出现了死循环 linux下buff、swap。。。。。。什么什么的区别 Linux查看资源使用情况，具体是什么函数比较消耗资源。 当你top命令时，每一列的含义是什么讲一下。 已经连接上了，服务器down了，客户端会作何反应。 连接池知道吗？讲一下。 io复用（select和epoll的区别） 要求回答关于进程操作等命令 如果某一进程造成CPU满了，是什么原因造成的，如何解决？ 如何查看系统性能/系统监测的命令 top命令中关于负载的命令是什么，loadavg知道吗 负载在操作系统里跟什么关联，怎么判断一个服务负载很高（不会，他解释说跟物理核数有关，任务比核数多会导致CPU频繁切换，负载高，比核数少会让CPU闲置） 随便说，说明操作系统是怎么应用的，当你进行一个操作时，操作系统在这个过程中都做了什么事情，操作系统怎么运转的（我说的是系统调用这个点） 怎么设计一个分布式存储系统 数据库 数据库引擎知道哪些，有什么区别 什么是索引，索引的存储结构是什么 给你一个sql语句,怎么优化 mysql索引方式 数据库提高查询效率的方法？索引的实现原理？ 操作系统内存管理？ 说一下第二范式和第三范式 索引的底层实现，为什么要用索引？加了索引，还是查询很慢，问题出在哪里？ 索引是可以优化查询，那还有其他优化方式吗 索引单列索引和多列索引有什么区别 有哪些Sql优化 聚集索引高效，为什么要有非聚集索引 为什么要建立索引，好处和坏处。 左连接、右连接、内连接讲一下。 ？mysql可不可以对多个字段建索引？ 数据结构 如何解决哈希表的冲突？ B+和B-的区别是什么？b树和b+树有什么却别，分别适合应用在什么场景 map的底层，红黑树的特点，为什么用红黑树而不用别的树 了解nat吗？ map中的key可不可以是结构体？是结构体的话怎么判断key重复 二叉树，平衡树 二叉树：红黑树，平衡二叉树（问的比较细，时间复杂度，特征） 堆栈的区别 堆栈的数据结构 一个email表，有id/name两列，用sql语句删除重复的name，只剩下一个（这个真的触及到盲区了，面试官说可以用join做） 场景题 如果有一个项目跑了两天之后崩溃了，怎么查这个原因？ 在Linux下有调试过吗？如果CPU达到100%，怎么调试？如果只有一个程序？如何确认是因为多个线程为响应造成的CPU达满？ 除了多线程和多进程之外，什么也可以用来实现并发，提高效率？ 对分布式系统的了解，多个地方的服务器怎么保证数据的一致性？ 遍历一个文件获取文件后十行（我说用tail命令，他让我不要用命令自己想办法实现，又说了好几种方法他都不满意，最后提示我用快慢指针解决） 设计题：设计一个类似于朋友圈或者微博的软件，上线之后看关注的好友的发的最新动态 情景题：有64皮马，一个马场里有8个跑道，用最少的场数确定跑的最快的4皮马， 买火车票经常出现无法访问，服务器负载过大，如何解决? 客户端方向和服务器方向思考 如何降低服务器上的连接数量。 了解过cache方面的编程么? TCP和UDP的使用场景。 服务端要给别人回包，但是对端套接字已经关了，服务器会出现什么情况 ?如果只是客户端的进程退出了，会怎么样，从网络交互方面回答 3、有一栋100层高的大楼，给你两个完全相同的玻璃球。假设从某一层开始，丢下玻璃球会摔碎，请问到哪一层会摔碎？（说思想，说了一种方法让继续改进），如果照你说的，先扔x层的思想，怎么确定这个分组。 linux命令中的mv，cp，mv,cp谁的效率快？为什么他们有什么区别？结合指针谈谈他们的实现？如果让你写一个mv,和cp，你会怎么设计？（有什么更好的办法？）。 缓存知道不？作用是什么？在数据库之间加缓存，缓存属于内存吗？数据库的数据在哪儿放着？ 10.编程题找10亿个数字前100大 udp报文最大发送大小 读文件找出积分最高的100个用户 大顶堆 treemap （其实我的思路是优先队列，但面试官要我用treemap） 算法： 找到一个链表环的入口 二进制转换成8进制 大文件去重排序 ，冒泡、归并、快排、选择排序的时间复杂度？ atoi 快排怎么实现的，讲思路 怎么用两个栈实现一个队列？有没有更好的办法 编写代码，求二叉树的宽度 将100,101,102,103,104,105以数组的形式写入到Dest.txt文件中，并以相反的顺序读出显示在屏幕上。 给出10G的数据，每条存储的一条ip地址，求重复率最高的top5 有s个人，围着桌子坐，随机选取一个人开始报数，报到m号时将他剔除，重新开始报数，依次进行，输出剔除序列（主要说数据结构） 对数据进行排序，选择算法进行排序（我选了快排加插入）？排序思想 海量数据进行排序 排序有没有考虑堆排？我说堆排适用于topk之类的算法 1~10000个数随机取出一个数，且乱序，找出这个数 链表找环 大根堆，小根堆。 一个单向链表，应该怎么样设计一个方法，看里面是否存在一个环 除了快慢指针还有什么办法 要求空间复杂度是O(1) 寻找数组中前10大的数据？时间复杂度？排序：如果数字基于有序：插入排序、希尔排序 如果数字毫无规则：快速排序 如果数字集中在某个较小的区域内，建立哈希表 升序数组找出和为指定数字的所有对(小米) 1 3 5 6 4 1类似这种先升后降的单链表 将其变成排好序的链表（小米） 一个数组中一个数出现两次，其它数都出现四次，要求找出这个数，要求时间复杂度nlogn，空间复杂度logn， 进程间通讯的方式有哪些？使用同一块共享内存的进程使用的虚拟地址相同吗？为什么？信号、信号量、共享内存、消息队列、管道、套接字有可能相同有可能不同，共享内存实际上已相当于文件，对于共享内存的文件映射到内存，如果两个进程完全相同的话，虚拟地址就是相同的，比如fork出来的进程和父进程访问同一个共享内存虚拟地址就可能相同。而进程如果有一点细微的不同，那么虚拟地址就会有差异 语言方面： i++是原子操作 多态 new一个对象，new之后java后台做了哪些工作 类加载过程 双亲委派模型的好处 怎样破坏双亲委派模型 互斥锁 读写锁 读写锁怎么用 手写实现一个读写锁（。。。不会） 用多线程手写一个生产者消费者模型（。。。也不会） 事务 并发事务造成的问题 事务的隔离级别 索引 聚集 非聚集 B+树 唯一性索引 普通索引 全文索引 最左前缀 联合索引 锁 表锁中共享读锁 独占写锁 行锁中共享锁 排他锁 乐观锁 悲观锁 间隙锁 （当时忘讲意向锁了） 项目中用到的索引有啥？ 实际应用中有用到锁机制吗？ 多线程锁的区别 Java访问修饰符的区别 为什么重写equals方法必须重写hashcode()方法。 如何实现子线程结束父线程才能结束 Spring AOP的原理 c++； 说下基类派生类的构造析构顺序？ 构造函数能不能是纯虚函数？ 不能的原因？ 设计模式 观察者模式是什么？大致说一下代码 单例模式 手写单例模式（写的双重if判断带锁的）-》问怎么优化？饿汉模式、懒汉模式 以及具体使用场景 使用单例模式应该注意什么为什么要使用单例模式（3）工厂模式 普通工厂 抽象工厂（4）观察者模式 Java面试题 多级缓存是怎么做的，怎么保证缓存中的数据是最新的 分布式下，怎么保证多个定时任务服务不会重复执行？ 一个用户订单表，一个用户有可能多个订单，查询出每个用户的最新订单（当时脑子抽筋了，想太复杂了，后面想了一下好像只要先group by 再 max（date）） Java 新建线程有哪几种方式 Java 内存区域，new出来的对象分配在哪里，堆内存里面是怎么划分的，为什么要分为新生代，老年代 线程有哪些状态，阻塞状态和等待状态有什么区别 数据库建立索引的原则，复合索引的命中规则 zookeeper 节点类型 说下 spring 的 IOC 与 AOP Java 反射有哪几种方式 -1000 到 1000 这两千个数用什么排序比较好 100 万个数用什么排序比较好 解决哈希冲突的方法 HashMap 的源码，把知道的都说说，后面追问 HashMap 扩容后怎么确定的元素在新的数组中的位置 B 树与 B+ 树的区别 redis 为什么快 怎么解决缓存穿透和缓存击穿，例如有黑客一直请求 id=-1 的数据怎么办？ Java的集合有了解吗，有哪几种 了解HashMap吗 HashMap的原理讲一下 HashMap和HashTable有什么区别 HashTable和ConCurrentHashMap的区别 HashMap的get实现是怎样的一个过程 多线程了解吗，讲一下线程的操作 sleep和wait的区别 线程池有了解吗 有哪几种线程池 线程池的优点 java的泛型了解吗，一般用在什么场景 泛型就是把类型参数化，在编译的时候才会确定具体的参数。可以用在类、接口、方法中。场景：我觉得当类 方法 接口 这些 当我们不确定使用的对象的类型是啥 或者 可能存在多种类型的可能的时候，可以使用泛型。最熟悉的就是集合类的实现都用到了泛型，这样我们在用的时候可以在&lt;&gt;中指定自己的需求，而不针对每种类型设计一个新的类。用上泛型可以提高类型的安全性，避免强转等。（有官方回答的求指导） 什么场景用String，什么场景用StringBuffer 看需求 是否存在线程安全问题，空间限制，时间限制 JVM怎么判断对象是否可以回收（可达性分析法） 可达性分析法中一般可以选哪些对象作为GC root，常量可以吗？虚拟机栈(栈帧中的本地变量表)中引用的对象。方法区中静态属性引用的对象。方法区中常量引用的对象。本地方法栈中(Native方法)引用的对象 springBoot启动流程 springMVC请求流程(不会，答适配器模式，json互相转换，就硬扯) springboot自动配置原理(好多次问到我这个了，我是真的不会呀，八股文一背就会，一说就废) 定义了事务但是事务失效的场景 拦截器原理(不会) mybatis动态SQL原理(不会) 已经在zookeeper中注册了的类，再次注册会怎样(知识盲区，不会) Redis的5种数据类型以及底层数据结构 ArrayList和LinkedList的区别和应用场景 上面的两个集合对应的线程安全类 LinkedBlockQueue源码 CopyOnWriteArrayList源码 HashMap源码 ConcurrentHashMap源码 问多线程了解吗(因为框架答得不好，就说了精通多线程，哈哈哈，头铁) 线程创建方式 FutureTask如何获取返回值 Java线程生命周期和操作系统生命周期 多线程的debug 如何解决并发问题 AQS源码 公平锁，非公平锁，可重入锁，不可重入锁怎么设计的 CountDownLatch源码 四种引用类型以及应用场景 threadlocal源码 synchronized修饰静态方法和非静态方法区别 字节码中两个monitorexit分别代表什么 读写屏障 synchronized可重入原理 从OS层面讲一下为什么synchronized要尽量减小加锁范围和避免重入 synchronized锁升级过程 如何判断对象锁状态 偏心锁的记录过程 什么情况下hash码处不能放线程ID hashcode如何计算 对象如何分配，垃圾如何回收，经历了哪些流程 很多线程同时往Eden区同时申请内存，分配对象，虚拟机怎么减少往同一块内存上分配对象的冲突 gc分代年龄最大值，为什么最大值是15 假设你设计jvm，你会在哪存gc年龄 cms是老年代垃圾回收器，它的搭档有哪些? cms为什么使用串行垃圾回收器作为备案 cms如何调优 G1垃圾回收过程 散射标记法(完全没听过) 颜色指针 B+树数据结构，聚簇索引，回表 没有唯一值，还有聚簇索引吗 explain会关注哪些信息 索引失效场景 jmm volatile 指令重排序，内存屏障 cas/aba问题 synchronized锁升级过程 自旋锁一定会提高效率？ 重量级锁的原理 线程池七大参数&amp;拒绝策略&amp;工作原理 JUC相关知道哪些？ 集合ArrayList，hashmap，linkedlist，concurrentHashmap原理&amp;扩容机制 知道哪些Gc算法，可达性分析算法什么对象做为根对象？ Tcp知道什么（说了保证可靠性的机制&amp;提高性能的机制） 幂等性的实现 线程池中的线程为什么可以一直处理任务不销毁 mvc 和 servlet 的关系 ping 在什么层 创建一个存放100个元素的 hashmap 应该设置多大保证不扩容 linux进程之间怎么通信的。(IPC) 多态问的很底层 两个方法，一个参数string，一个参数obj， 调用传参null，问调用哪个方法， 不会 10亿个数找两个重复数字 10亿个数找最小10个","categories":[{"name":"计算机网络","slug":"Network","permalink":"https://songsong.ink/categories/Network/"}],"tags":[{"name":"review","slug":"review","permalink":"https://songsong.ink/tags/review/"}]},{"title":"负载均衡","slug":"nginx负载均衡","date":"2021-09-18T16:44:16.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/09/18/a3e5f334146b.html","link":"","permalink":"https://songsong.ink/2021/09/18/a3e5f334146b.html","excerpt":"","text":"负载均衡算法1. 轮循均衡（Round Robin）每一次来自网络的请求轮流分配给内部中的服务器，从 1 至N然后重新开始。此种均衡算法适合 于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。 2. 权重轮循均衡（Weighted Round Robin）根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请 求。例如：服务器A的权值被设计成 1，B 的权值是 3，C的权值是 6，则服务器A、B、C将分 别接受到10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用 率，避免低性能的服务器负载过重。 3. 随机均衡（Random）把来自网络的请求随机分配给内部中的多个服务器。 4. 权重随机均衡（Weighted Random）此种均衡算法类似于权重轮循算法，不过在处理请求分担时是个随机选择的过程。 5. 响应速度均衡（Response Time 探测时间）负载均衡设备对内部各服务器发出一个探测请求（例如 Ping），然后根据内部中各服务器对探测 请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映 服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间 6. 最少连接数均衡（Least Connection） 最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在 处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡 更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如 FTP。 7. 处理能力均衡（CPU、内存）此种均衡算法将把服务请求分配给内部中处理负荷（根据服务器CPU型号、CPU数量、内存大小 及当前连接数等换算而成）最轻的服务器，由于考虑到了内部服务器的处理能力及当前网络运行 状况，所以此种均衡算法相对来说更加精确，尤其适合运用到第七层（应用层）负载均衡的情况 下。 8. DNS响应均衡（Flash DNS）在此均衡算法下，分处在不同地理位置的负载均衡设备收到同一个客户端的域名解析请求，并在 同一时间内把此域名解析成各自相对应服务器的 IP 地址并返回给客户端，则客户端将以最先收到 的域名解析 IP 地址来继续请求服务，而忽略其它的 IP 地址响应。在种均衡策略适合应用在全局负 载均衡的情况下，对本地负载均衡是没有意义的。 9. 哈希算法一致性哈希一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往 该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 10. IP 地址散列（保证客户端服务器对应关系稳定）通过管理发送方 IP 和目的地 IP 地址的散列，将来自同一发送方的分组(或发送至同一目的地的分 组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信 时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处 理。 11. URL 散列通过管理客户端请求URL 信息的散列，将发送至相同URL 的请求转发至同一服务器的算法。","categories":[{"name":"nginx","slug":"nginx","permalink":"https://songsong.ink/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://songsong.ink/tags/nginx/"}]},{"title":"spring面试","slug":"spring面试","date":"2021-09-09T16:02:43.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/09/09/a1a07dd22c32.html","link":"","permalink":"https://songsong.ink/2021/09/09/a1a07dd22c32.html","excerpt":"","text":"","categories":[{"name":"spring","slug":"spring","permalink":"https://songsong.ink/categories/spring/"}],"tags":[]},{"title":"redis常用操作哦","slug":"redis常用操作","date":"2021-08-23T20:43:53.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/23/5ed71c7fdf57.html","link":"","permalink":"https://songsong.ink/2021/08/23/5ed71c7fdf57.html","excerpt":"","text":"1.redis的五种数据结构 字符串String 哈希表hash 列表list 集合set 有序集合zset 1.1字符串的常用操作 set key value 存储一个键值对 mset key value key value … 存储多个键值对 setnx key value 存储一个不存在的键值对 get key 获取一个value mget key … 批量获取key的value del key … 批量删除键值对 expire key seconds 设置过期时间 incr key key的整数值加1 decr key key的整数值减1 incrby key increment key的值加increment decrby key decrement key的值减去decrement 规范化自己的代码风格，使用缓存优化效率，在高并发情况下的边界问题问题处理。学习优秀的开源项目源码，并且加上自己的实现完成自己的开发。","categories":[{"name":"redis","slug":"redis","permalink":"https://songsong.ink/categories/redis/"}],"tags":[]},{"title":"ubuntu修改hostname","slug":"ubuntu修改hostname","date":"2021-08-20T15:40:40.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/20/3f9300d23ecc.html","link":"","permalink":"https://songsong.ink/2021/08/20/3f9300d23ecc.html","excerpt":"","text":"修改/etc/cloud/cloud.cfg文件123preserve_hostname: false修改preserve_hostname: true 执行命令 hostnamectl set-hostname 主机名1hostnamectl set-hostname testname","categories":[{"name":"linux","slug":"linux","permalink":"https://songsong.ink/categories/linux/"}],"tags":[{"name":"ubuntu hostname","slug":"ubuntu-hostname","permalink":"https://songsong.ink/tags/ubuntu-hostname/"}]},{"title":"linux端口号","slug":"linux端口号","date":"2021-08-20T15:17:13.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/20/c4bf1f45066d.html","link":"","permalink":"https://songsong.ink/2021/08/20/c4bf1f45066d.html","excerpt":"","text":"第一种：lsof -i:端口号 第二种：netstat -nltp | grep 端口号 -a：显示本机所有连接和监听地端口 -n：网络IP地址的形式，显示当前建立的有效连接和端口 -r：显示路由表信息 -s：显示按协议的统计信息 -v：显示当前有效的连接 -t：显示所有TCP协议连接情况 -u：显示所有UDP协议连接情况 -i：显示自动配置端口的状态 -l：仅仅显示连接状态为listening的服务网络状态 -p：显示pid/program name TCP连接的几种状态 ESTABLISHED 已建立 CLOSED 已关闭 LISTENING 正在监听 FIN-WAIT-2 等待连接关闭 TIME-WAIT 等待足够时间，确保服务器正常关闭该连接","categories":[{"name":"linux","slug":"linux","permalink":"https://songsong.ink/categories/linux/"}],"tags":[]},{"title":"hashmap","slug":"hashmap","date":"2021-08-17T15:01:51.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/17/18c3a0674c7f.html","link":"","permalink":"https://songsong.ink/2021/08/17/18c3a0674c7f.html","excerpt":"","text":"HashMap源码分析（jdk1.8，保证你能看懂） 现在的面试当中凡是那些大厂，基本上都会问到一些关于HashMap的问题了，而且这个集合在开发中也经常会使用到。于是花费了大量的时间去研究分析写了这篇文章。本文是基于jdk1.8来分析的。篇幅较长，但是都是循序渐进的。耐心读完相信你会有所收获。 一、带着问题分析 这篇文章，希望能解决以下问题。 （1）HashMap的底层数据结构是什么？ （2）HashMap中增删改查操作的底部实现原理是什么？ （3）HashMap是如何实现扩容的？ （4）HashMap是如何解决hash冲突的？ （7）HashMap为什么是非线程安全的？ 下面我们就带着这些问题，揭开HashMap的面纱。 二、认识HashMap HashMap最早是在jdk1.2中开始出现的，一直到jdk1.7一直没有太大的变化。但是到了jdk1.8突然进行了一个很大的改动。其中一个最显著的改动就是： 之前jdk1.7的存储结构是数组+链表，到了jdk1.8变成了数组+链表+红黑树。 另外，HashMap是非线程安全的，也就是说在多个线程同时对HashMap中的某个元素进行增删改操作的时候，是不能保证数据的一致性的。 下面我们就开始一步一步的分析。 三、深入分析HashMap 1、底层数据结构 为了进行一个对比分析，我们先给出一个jdk1.7的存储结构图 从上图我们可以看到，在jdk1.7中，首先是把元素放在一个个数组里面，后来存放的数据元素越来越多，于是就出现了链表，对于数组中的每一个元素，都可以有一条链表来存储元素。这就是有名的“拉链式”存储方法。 就这样用了几年，后来存储的元素越来越多，链表也越来越长，在查找一个元素时候效率不仅没有提高（链表不适合查找，适合增删），反倒是下降了不少，于是就对这条链表进行了一个改进。如何改进呢？就是把这条链表变成一个适合查找的树形结构，没错就是红黑树。于是HashMap的存储数据结构就变成了下面的这种。 我们会发现优化的部分就是把链表结构变成了红黑树。原来jdk1.7的优点是增删效率高，于是在jdk1.8的时候，不仅仅增删效率高，而且查找效率也提升了。 注意：不是说变成了红黑树效率就一定提高了，只有在链表的长度不小于8，而且数组的长度不小于64的时候才会将链表转化为红黑树， 问题一：什么是红黑树呢？ 红黑树是一个自平衡的二叉查找树，也就是说红黑树的查找效率是非常的高，查找效率会从链表的o(n)降低为o(logn)。如果之前没有了解过红黑树的话，也没关系，你就记住红黑树的查找效率很高就OK了。 问题二：为什么不一下子把整个链表变为红黑树呢？ 这个问题的意思是这样的，就是说我们为什么非要等到链表的长度大于等于8的时候，才转变成红黑树？在这里可以从两方面来解释 （1）构造红黑树要比构造链表复杂，在链表的节点不多的时候，从整体的性能看来， 数组+链表+红黑树的结构可能不一定比数组+链表的结构性能高。就好比杀鸡焉用牛刀的意思。 （2）HashMap频繁的扩容，会造成底部红黑树不断的进行拆分和重组，这是非常耗时的。因此，也就是链表长度比较长的时候转变成红黑树才会显著提高效率。 OK，到这里相信我们对hashMap的底层数据结构有了一个认识。现在带着上面的结构图，看一下如何存储一个元素。 2、存储元素put 我们在存储一个元素的时候，大多是使用下面的这种方式。 12345678public class Test &#123; public static void main(String[] args) &#123; HashMap&lt;String, Integer&gt; map= new HashMap&lt;&gt;(); //存储一个元素 map.put(&quot;张三&quot;, 20); &#125;&#125; 在这里HashMap&lt;String, Integer&gt;，第一个参数是键，第二个参数是值，合起来叫做键值对。存储的时候只需要调用put方法即可。那底层的实现原理是怎么样的呢？这里还是先给出一个流程图 上面这个流程，不知道你能否看到，红色字迹的是三个判断框，也是转折点，我们使用文字来梳理一下这个流程： （1）第一步：调用put方法传入键值对 （2）第二步：使用hash算法计算hash值 （3）第三步：根据hash值确定存放的位置，判断是否和其他键值对位置发生了冲突 （4）第四步：若没有发生冲突，直接存放在数组中即可 （5）第五步：若发生了冲突，还要判断此时的数据结构是什么？ （6）第六步：若此时的数据结构是红黑树，那就直接插入红黑树中 （7）第七步：若此时的数据结构是链表，判断插入之后是否大于等于8 （8）第八步：插入之后大于8了，就要先调整为红黑树，在插入 （9）第九步：插入之后不大于8，那么就直接插入到链表尾部即可。 上面就是插入数据的整个流程，光看流程还不行，我们还需要深入到源码中去看看底部是如何按照这个流程写代码的。 鼠标聚焦在put方法上面，按一下F3，我们就能进入put的源码。来看一下： 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 也就是说，put方法其实调用的是putVal方法。putVal方法有5个参数： （1）第一个参数hash：调用了hash方法计算hash值 （2）第二个参数key：就是我们传入的key值，也就是例子中的张三 （3）第三个参数value：就是我们传入的value值，也就是例子中的20 （4）第四个参数onlyIfAbsent：也就是当键相同时，不修改已存在的值 （5）第五个参数evict ：如果为false，那么数组就处于创建模式中，所以一般为true。 知道了这5个参数的含义，我们就进入到这个putVal方法中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //第一部分 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //第二部分 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //第三部分 else &#123; Node&lt;K,V&gt; e; K k; //第三部分第一小节 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //第三部分第二小节 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //第三部分第三小节 else &#123; for (int binCount = 0; ; ++binCount) &#123; //第三小节第一段 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //第三小节第一段 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //第三小节第三段 p = e; &#125; &#125; //第三部分第四小节 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //第四部分 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 乍一看，这代码完全没有读下去的欲望，第一次看的时候真实恶心到想吐，但是结合上一开始画的流程图再来分析，相信就会好很多。我们把代码进行拆分（整体分了四大部分）： （1）Node&lt;K,V&gt;[] tab中tab表示的就是数组。Node&lt;K,V&gt; p中p表示的就是当前插入的节点 （2）第一部分： 12if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; 这一部分表示的意思是如果数组是空的，那么就通过resize方法来创建一个新的数组。在这里resize方法先不说明，在下一小节扩容的时候会提到。 （3）第二部分： 12if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); i表示在数组中插入的位置，计算的方式为(n - 1) &amp; hash。在这里需要判断插入的位置是否是冲突的，如果不冲突就直接newNode，插入到数组中即可，这就和流程图中第一个判断框对应了。 如果插入的hash值冲突了，那就转到第三部分，处理冲突 （4）第三部分： 123456789101112131415161718192021222324252627282930313233343536else &#123; Node&lt;K,V&gt; e; K k; //第三部分a if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //第三部分b else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //第三部分c else &#123; for (int binCount = 0; ; ++binCount) &#123; //第三小节第一段 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //第三小节第一段 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //第三小节第三段 p = e; &#125; &#125; //第三部分d if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125;&#125; 我们会看到，处理冲突还真是麻烦，好在我们对这一部分又进行了划分 a）第三部分第一小节： 123if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; 在这里判断table[i]中的元素是否与插入的key一样，若相同那就直接使用插入的值p替换掉旧的值e。 b）第三部分第二小节： 12else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); 判断插入的数据结构是红黑树还是链表，在这里表示如果是红黑树，那就直接putTreeVal到红黑树中。这就和流程图里面的第二个判断框对应了。 c）第三部分第三小节： 123456789101112131415161718//第三部分celse &#123; for (int binCount = 0; ; ++binCount) &#123; //第三小节第一段 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //第三小节第一段 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //第三小节第三段 p = e; &#125;&#125; 如果数据结构是链表，首先要遍历table数组是否存在，如果不存在直接newNode(hash, key, value, null)。如果存在了直接使用新的value替换掉旧的。 注意一点：不存在并且在链表末尾插入元素的时候，会判断binCount &gt;= TREEIFY_THRESHOLD - 1。也就是判断当前链表的长度是否大于阈值8，如果大于那就会把当前链表转变成红黑树，方法是treeifyBin。这也就和流程图中第三个判断框对应了。 （5）第四部分： 1234if (++size &gt; threshold) resize();afterNodeInsertion(evict);return null; 插入成功之后，还要判断一下实际存在的键值对数量size是否大于阈值threshold。如果大于那就开始扩容了。 3、扩容 为什么扩容呢？很明显就是当前容量不够，也就是put了太多的元素。为此我们还是先给出一个流程图，再来进行分析。 这个扩容就比较简单了，HaspMap扩容就是就是先计算 新的hash表容量和新的容量阀值，然后初始化一个新的hash表，将旧的键值对重新映射在新的hash表里。如果在旧的hash表里涉及到红黑树，那么在映射到新的hash表中还涉及到红黑树的拆分。整个流程也符合我们正常扩容一个容量的过程，我们根据流程图结合代码来分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //第一部分：扩容 if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //第二部分：设置阈值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //第三部分：旧数据保存在新数组里面 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //只有一个节点，通过索引位置直接映射 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果是红黑树，需要进行树拆分然后映射 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; //如果是多个节点的链表，将原链表拆分为两个链表 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //链表1存于原索引 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //链表2存于原索引加上原hash桶长度的偏移量 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 这代码量同样让人恶心，不过我们还是分段来分析： （1）第一部分： 12345678910//第一部分：扩容if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold&#125; 根据代码也能看明白：首先如果超过了数组的最大容量，那么就直接将阈值设置为整数最大值，然后如果没有超过，那就扩容为原来的2倍，这里要注意是oldThr &lt;&lt; 1，移位操作来实现的。 （2）第二部分： 1234567891011121314151617//第二部分：设置阈值else if (oldThr &gt; 0) //阈值已经初始化了，就直接使用 newCap = oldThr;else &#123; // 没有初始化阈值那就初始化一个默认的容量和阈值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);&#125;if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);&#125;//为当前的容量阈值赋值threshold = newThr;@SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;)Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];table = newTab; 首先第一个else if表示如果阈值已经初始化过了，那就直接使用旧的阈值。然后第二个else表示如果没有初始化，那就初始化一个新的数组容量和新的阈值。 （3）第三部分 第三部分同样也很复杂，就是把旧数据复制到新数组里面。这里面需要注意的有下面几种情况： A：扩容后，若hash值新增参与运算的位=0，那么元素在扩容后的位置=原始位置 B：扩容后，若hash值新增参与运算的位=1，那么元素在扩容后的位置=原始位置+扩容后的旧位置。 hash值新增参与运算的位是什么呢？我们把hash值转变成二进制数字，新增参与运算的位就是倒数第五位。 这里面有一个非常好的设计理念，扩容后长度为原hash表的2倍，于是把hash表分为两半，分为低位和高位，如果能把原链表的键值对， 一半放在低位，一半放在高位，而且是通过e.hash &amp; oldCap == 0来判断，这个判断有什么优点呢？ 举个例子：n = 16，二进制为10000，第5位为1，e.hash &amp; oldCap 是否等于0就取决于e.hash第5 位是0还是1，这就相当于有50%的概率放在新hash表低位，50%的概率放在新hash表高位。 OK，到这一步基本上就算是把扩容这一部分讲完了，还有一个问题没有解决，也就是说存储的原理讲明白了，存储的元素多了如何扩容也明白了，扩容之后出现了地址冲突怎么办呢？ 4、解决地址冲突 解决地址冲突的前提是计算的hash值出现了重复，我们就先来看看HashMap中，是如何计算hash值的。 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 代码是超级简单，hash值其实就是通过hashcode与16异或计算的来的，为什么要使用异或运算呢？画一张图你就明白了： 也就是说，通过异或运算能够是的计算出来的hash比较均匀，不容易出现冲突。但是偏偏出现了冲突现象，这时候该如何去解决呢？ 在数据结构中，我们处理hash冲突常使用的方法有：开发定址法、再哈希法、链地址法、建立公共溢出区。而hashMap中处理hash冲突的方法就是链地址法。 这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。 相信大家都能看明白，出现地址冲突的时候，一个接一个排成一条链就OK了。正好与HashMap底层的数据结构相呼应。 5、构造一个HashMap 上面可能出现的问题，我们都已经说明了，关于他的构造方法却姗姗来迟。下面我们好好说一下他的构造方法： 他的构造方法一共有四个： 第一个： 123public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125; 第二个： 123public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; 第三个： 1234public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 第四个： 123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; 这四个构造方法很明显第四个最麻烦，我们就来分析一下第四个构造方法，其他三个自然而然也就明白了。上面出现了两个新的名词：loadFactor和initialCapacity。我们一个一个来分析： （1）initialCapacity初始容量 官方要求我们要输入一个2的N次幂的值，比如说2、4、8、16等等这些，但是我们忽然一个不小心，输入了一个20怎么办？没关系，虚拟机会根据你输入的值，找一个离20最近的2的N次幂的值，比如说16离他最近，就取16为初始容量。 （2）loadFactor负载因子 负载因子，默认值是0.75。负载因子表示一个散列表的空间的使用程度，有这样一个公式：initailCapacity*loadFactor=HashMap的容量。 所以负载因子越大则散列表的装填程度越高，也就是能容纳更多的元素，元素多了，链表大了，所以此时索引效率就会降低。反之，负载因子越小则链表中的数据量就越稀疏，此时会对空间造成烂费，但是此时索引效率高。 为什么默认值会是0.75呢？我们截取一段jdk文档： 英语不好的人看的我真是一脸懵逼，不过好在大概意思还能明白。看第三行Poisson_distribution这不就是泊淞分布嘛。而且最关键的就是 当桶中元素到达8个的时候，概率已经变得非常小，也就是说用0.75作为加载因子，每个碰撞位置的链表长度超过８个是几乎不可能的。当桶中元素到达8个的时候，概率已经变得非常小，也就是说用0.75作为加载因子，每个碰撞位置的链表长度超过８个是几乎不可能的。 6、HashMap为什么是非线程安全的？ 想要解决这个问题，答案很简单，因为源码里面方法全部都是非线程安全的呀，你根本找不到synchronized这样的关键字。保证不了线程安全。于是出现了ConcurrentHashMap。","categories":[],"tags":[]},{"title":"进程间通信","slug":"进程间通信","date":"2021-08-16T20:27:19.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/16/f5eb7f7f9a8b.html","link":"","permalink":"https://songsong.ink/2021/08/16/f5eb7f7f9a8b.html","excerpt":"","text":"进程间的通信方式 管道 消息队列 共享内存 信号量 信号 Socket 管道管道方式举例: | 就是一个匿名管道将ps aux的输出作为后一个命令的输入，而且很显然管道是单向的。双向通信就需要两个管道。 1ps aux | grep mysql 管道分类 匿名管道 | （用完就销毁） 命名管道 FIFO （数据是先进先出的形式） 1mkfifo myPipe myPipe 就是我们创建的管道的名称，linux一切皆文件这个pipe的文件类型是P 12song@MateBooke13:~$ ls -l pipeprw-r--r-- 1 song song 0 Aug 16 20:51 pipe 往管道写入数据 12echo &quot;hello&quot; &gt; pipe //写入数据//卡住 管道的原理管道就是内核的一串缓存，从管道的一段写入数据，实际上就是缓存在内核中的，另一端读取也就是从内核中读取这段数据。另外管道传输的数据是无格式的且大小受限。 匿名管道必须在父子进程中进行。而命名管道无此限制 在shell中执行 A|B，A和B都是shell创建的子进程。 缺点 管道的通信方式效率很低，不适合在进程间频繁的交换数据。 消息队列消息队列可以解决管道的缺点。A进程给B发消息，A把数据放到消息队列里面就可以走了。B需要的时候就去取消息队列是保存在内核中的消息链表，发送前要确认好数据格式。消息队列随内核存在。 缺点 通信不及时 邮件大小有限制 通信过程存在切换内核态开销 共享内存共享内存是为了解决消息队列存在内核态和用户态切换的问题。共享内存的机制就是拿出一块虚拟地址，映射到相同的物理内存中，这个对内存的读取另一个进程马上就能看到。 缺点 共享内存区域在多个进程同时修改同一个共享内存时，内容被覆盖 信号量信号量时为了防止多进程竞争共享资源的一种保护机制（PV操作实现进程的互斥与同步）以上都是常规状态下的工作模式 信号linux下为了响应各种事件，提供了几十种信号，分别带别不同的意义。（kill -l 查看） Ctrl +C 产生SIGINT信号终止进程 CTRL+Z SIGTSTP 停止该进程 kill -9 1050 表示给PID1050发送SIGKILL信号，来立即结束进程 Socketsocket来实现跨网络通信","categories":[{"name":"进程","slug":"进程","permalink":"https://songsong.ink/categories/%E8%BF%9B%E7%A8%8B/"}],"tags":[]},{"title":"HTTP1.1如何优化","slug":"HTTP1.1优化","date":"2021-08-16T19:13:29.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/16/dd6d47563dee.html","link":"","permalink":"https://songsong.ink/2021/08/16/dd6d47563dee.html","excerpt":"","text":"三种优化思路 如何避免发HTTP请求 如何减少HTTP请求 如何减少HTTP请求数据大小 如何避免发HTTP请求 使用缓存 对于一些重复性的请求把请求响应缓存在本地。url作为Key响应作为value，同时设置过期时间。过期后的重复请求在请求时携带摘要，服务端验证将服务端数据和摘要比较看是否修改，没有修改就返回304 NOt Modified。 如何减少HTTP请求 合并请求 （小数据合并到一起请求） 减少重定向次数 延迟发送请求（按需加载） 减少HTTP响应的数据大小 无损压缩 有损压缩","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://songsong.ink/categories/HTTP/"}],"tags":[{"name":"HTTP.1","slug":"HTTP-1","permalink":"https://songsong.ink/tags/HTTP-1/"}]},{"title":"排序算法得性质","slug":"datastruct/data","date":"2021-08-16T19:13:29.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/16/0f646613617c.html","link":"","permalink":"https://songsong.ink/2021/08/16/0f646613617c.html","excerpt":"","text":"算法种类 最好情况 平均情况 最坏情况 空间复杂度 是否稳定 直接插入排序 冒泡排序 简单选择排序 希尔排序 快速排序 堆排序 2路归并排序 基数排序","categories":[],"tags":[]},{"title":"一次git误删除本地commit的补救","slug":"一次git误删除本地commit的补救","date":"2021-08-14T20:44:23.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/14/aae24ddbc03a.html","link":"","permalink":"https://songsong.ink/2021/08/14/aae24ddbc03a.html","excerpt":"","text":"事故起因为了保证push到远端时commit是干净的，准备对本地的commit进行合并，此时处于马上要下班的兴奋时刻，手一哆嗦把误点了drop。准备提交的所有commit消失不见 问题处理 git status git reflog –date=iso 查看git的记录找到当时的commit git checkout -b tmp a823ba6 ## a823ba6为删除的最后一个commit的id git log git branch git checkout kfapi8-11-19-54 git branch git branch -m kfapi8-11-19-54-back git checkout tmp git branch -m kfapi8-11-19-54","categories":[{"name":"git","slug":"git","permalink":"https://songsong.ink/categories/git/"}],"tags":[]},{"title":"linux create service","slug":"linux-create-service","date":"2021-08-05T13:12:25.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/05/9877030524ce.html","link":"","permalink":"https://songsong.ink/2021/08/05/9877030524ce.html","excerpt":"","text":"linux服务配置文件 12### 创建服务文件 vim /etc/systemd/system/EmbyMedia_GoogleMovie_play.service 1234567891011121314[Unit]Description=RcloneAssertPathIsDirectory=/mnt/googledriveAfter=network-online.target[Service]Type=simpleExecStart=/usr/bin/rclone mount googledrive:movies /mnt/googledrive --umask 0000 --default-permissions --allow-non-empty --allow-other --buffer-size 32M --dir-cache-time 12h --vfs-cache-mode writes --vfs-read-chunk-size 64M --vfs-read-chunk-size-limit 1GExecStop=/bin/fusermount -u /mnt/googledrive Restart=on-abortUser=root[Install]WantedBy=default.target 123456#重载daemon，让新的服务文件生效systemctl daemon-reload#启动rclonesystemctl start EmbyMedia_VIP_Movie_play EmbyMedia_VIP_TVasia_play EmbyMedia_VIP_TVnf_play#设置开机启动：systemctl","categories":[{"name":"linux","slug":"linux","permalink":"https://songsong.ink/categories/linux/"}],"tags":[]},{"title":"linux命令","slug":"linux命令","date":"2021-08-05T12:59:25.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/05/1982596e3a33.html","link":"","permalink":"https://songsong.ink/2021/08/05/1982596e3a33.html","excerpt":"","text":"查看端口被那个进程占用 12netstat -lnp|grep 7000 lsof -i :22","categories":[{"name":"linux","slug":"linux","permalink":"https://songsong.ink/categories/linux/"}],"tags":[]},{"title":"git命令","slug":"git命令","date":"2021-08-03T12:49:53.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/03/d105761cf6b8.html","link":"","permalink":"https://songsong.ink/2021/08/03/d105761cf6b8.html","excerpt":"","text":"新建feature分支 git checkout -b feature_x checkout 切换 -b feature_x branch feature_x 新建分支x 查看分支 git branch 删除本地分支 git branch -d feature_x 删除远程分支 git push origin –delete feature_x git rebase master -&gt; git rebase –contionue 纳入版本控制 git add xxx.xx git pull 拉代码 git push 推代码 git cherry-pick 将指定的提交（commit）应用于其他分支。","categories":[{"name":"git","slug":"git","permalink":"https://songsong.ink/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://songsong.ink/tags/git/"}]},{"title":"spingboot配置","slug":"spingboot配置","date":"2021-08-02T14:43:22.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/02/5c1a3fdb1604.html","link":"","permalink":"https://songsong.ink/2021/08/02/5c1a3fdb1604.html","excerpt":"","text":"使用profile切换配置环境spring boot允许你通过命名约定按照一定的格式(application-{profile}.properties)来定义多个配置文件，然后通过在application.properyies通过spring.profiles.active来具体激活一个或者多个配置文件，如果没有没有指定任何profile的配置文件的话，spring boot默认会启动application-default.properties。 vm参数配置 -Dspring.profiles.active123456789101112groovyScript(&quot;def result=&#x27;&#x27;; def params=\\&quot;$&#123;_1&#125;\\&quot;.replaceAll(&#x27;[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]&#x27;, &#x27;&#x27;).split(&#x27;,&#x27;).toList(); result+= params.size() += &#x27;\\\\n&#x27;; for(i = 0; i &lt; params.size(); i++) &#123; if(params[i] == &#x27;&#x27;) return result; if(i==0) result += &#x27;\\\\n&#x27;; result+=&#x27; * @param &#x27; + params[i] + ((i &lt; params.size() - 1) ? &#x27;\\\\n&#x27; : &#x27;&#x27;) &#125;; return result&quot;, methodParameters())","categories":[{"name":"springboot","slug":"springboot","permalink":"https://songsong.ink/categories/springboot/"}],"tags":[]},{"title":"idea常用快捷键总结","slug":"idea常用快捷键总结","date":"2021-08-02T14:12:51.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/08/02/5046cc886a09.html","link":"","permalink":"https://songsong.ink/2021/08/02/5046cc886a09.html","excerpt":"","text":"ctrl+shift+(+/-)展开全部折叠全部 ctrl+（+/-） 展开折叠当前方法 ctrl+shift+U 全部转换为大写or小写 ctrl+H 查看类继承关系，不能看实现接口 ctrl + alt + u 既能看继承关系也能看接口","categories":[{"name":"idea","slug":"idea","permalink":"https://songsong.ink/categories/idea/"}],"tags":[]},{"title":"企业微信客服接入","slug":"企业微信客服接入","date":"2021-07-29T20:18:04.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/29/05a78b7aff72.html","link":"","permalink":"https://songsong.ink/2021/07/29/05a78b7aff72.html","excerpt":"","text":"微信客服可实现的功能 可将企业员工配置为微信客服的接待人员，在企业微信里接收和回复用户在微信内、外发起的咨询消息 可在企业微信里通过API来管理微信客服帐号、分配客服会话和收发客服消息等。 可使用客服工具栏、「升级服务」等工具 微信客服的接入场景1、在微信内接入 在视频号中接入：企业在企业微信管理后台的“微信客服应用-在视频号中接入”处，选择企业已绑定的视频号，并选择在该视频号中接入的微信客服即可。 在微信内网页接入 在公众号中接入 在小程序中接入 | 小程序API 在搜一搜品牌官方区中接入 在微信支付凭证处接入2、在微信外接入 在App中接入 | SDK 在微信外网页接入开启api 开启API之后，微信联系人与企业接待人员的所有消息与事件都回调给企业，企业可以调用API来收发消息、分配会话等 注意： 企业须已在在企业微信里使用微信客服且已开启API，才能正常在企业微信里调用微信客服相关API。 开启API后，仅可通过API来管理客服帐号、分配客服会话和收发客服消息，开发者请做好处理。 Api客服账号管理 添加客服帐号 删除客服帐号 删除客服帐号 获取客服帐号列表 获取客服帐号链接 接待人员管理 添加接待人员：添加指定客服帐号的接待人员。 删除接待人员：删除接待人员 获取接待人员列表：获取某个客服帐号的接待人员列表 分配客服会话","categories":[{"name":"企业微信接入","slug":"企业微信接入","permalink":"https://songsong.ink/categories/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%8E%A5%E5%85%A5/"}],"tags":[]},{"title":"秒杀缓存优化","slug":"秒杀缓存优化","date":"2021-07-29T20:18:04.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/29/b80307f408ca.html","link":"","permalink":"https://songsong.ink/2021/07/29/b80307f408ca.html","excerpt":"","text":"缓存优化思路梳理使用Redis做一级缓存首先对接口进行压测。无缓存的情况下QPS只有80. 优化步骤首先考虑所有请求都直接读写mysql肯定是不行的。那么第一想到的是加redis缓存商品数据。查询请求进来首先查询redis缓存，缓存不存在再去读数据库，最后更新缓存。 修改日志级别到warn，减少无效日志 性能提升10%。日志也会影响性能。 不走网关直接走原始服务器，性能提升。（网关处理也会影响性能） 进行三个优化步骤后达到1000QPS。 进一步思考请求Redis会走网络请求网卡也是影响性能瓶颈的原因。而且存入redis会有序列化和反序列化的开销。会对性能产生影响。此时考虑加入本地缓存，在高并发环境下使用ConcurrentHashMap做缓存。此时考虑缓存不能无限增长的，要对缓存加入淘汰策略。此时采用经典的LRU作为淘汰策略。 缓存击穿问题使用缓存时，会出现大量缓存失效的问题，此时会有大量的请求去读取数据库。大量的请求同时请求数据库会导致数据库宕机。此种情况下要对数据的读取操作进行同步操作，阻塞大量的数据库请求。考虑到服务时集群形式，此时采用分布式锁来同步读取操作。 可以实现分布式锁的有： Redis Redssion Zookeeper 最后选取了Zookeeper，Redis和Redssion会有死锁问题。 缓存穿透问题当大量id不存在的请求过去会导致瞬时大量的读取数据库请求。这就是缓存穿透问题。 解决该问题的解决方案会有三个特性： 快：处理要快 准：判断要准确 省：可以压缩数据 redis方案首先，快这个特性就要求数据要存储到内存中，此时可以考虑将所有的id存到redis中，可以实现快速准确的判断，但是在数据量很大的情况下会占用大量内存。此时可以考虑对数据进行压缩，但是要保证依然可以判断出id是否存在。 布隆过滤器可以用布隆过滤器，布隆过滤器实际上就是一种压缩数据的方案，可以对数据是否存在进行判断。此时布隆过滤器放到redis。不需要每个实例维护一份布隆过滤器。 布隆过滤器原理布隆过滤器的组成： 多个hash函数 位数组 布隆过滤器启动时使用多个hash函数对id进行计算。然后将计算出的多个值在位数组中位置标为1。当要判断的时候就会重复该过程，同时去判断得出的结果的对应位置是不是都为1，主要有一个不为0就说明不存在。 布隆过略器准确性影响因素： 哈希函数的个数 位数组的长度 多级缓存数据不一致问题","categories":[{"name":"缓存","slug":"cache","permalink":"https://songsong.ink/categories/cache/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://songsong.ink/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"面试题汇总","slug":"面试题汇总","date":"2021-07-28T14:07:06.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/28/cdc84b02548f.html","link":"","permalink":"https://songsong.ink/2021/07/28/cdc84b02548f.html","excerpt":"","text":"服务器性能瓶颈服务器性能瓶颈主要在四个方面： 网卡 cpu 内存 IO 计算机网络套接字网络中通过ip地址来标识和区别不同的主机，通过端口号来标识和区分一台主机中的不同应用进程。在网络中采用发送方和接受方的套接字（socket）组合来识别端点。所谓套接字，实际上是一个通信端点即 套接字 = （主机IP地址，端口号） 套接字唯一的标识网络中的一台主机和其上的一个应用（进程） TCP如何保证可靠性传输tcp是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。 什么是超时重传在发送数据时，设定一个计时器，当超过指定的时间后没有收到对方的ACK确认应答报文，就会重新发送接着这就是超时重传 什么时候发生超时重传TCP会在一下两种情况发送超时重传 数据包丢失 确认应答丢失 什么是RTT（Round—trip TIme 往返时延）[x] RTT就是数据从网络一端传送到另一端所需的时间 RTO（Retransmission Timeout）RTO：耗时重传时间。 当RTO过大时，重发就慢，丢了很长时间才会重发，没有效率，性能差。 当RTO过小时，会导致可能并没有丢就重发，于是重发的快，会导致网络拥塞，导致更多的超时，更多超时会导致更多的重发 根据上述情况，超时重传时间RTO的值应该略大约报文往返RTO的值 快速重传","categories":[{"name":"面试汇总","slug":"面试汇总","permalink":"https://songsong.ink/categories/%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/"}],"tags":[]},{"title":"TCP VS UDP","slug":"TCP-VS-UDP","date":"2021-07-27T20:45:47.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/27/b949100f3f59.html","link":"","permalink":"https://songsong.ink/2021/07/27/b949100f3f59.html","excerpt":"","text":"TCP和UDP区别：1.连接 TCP是面向连接的传输层协议，需要先建立连接。 UDP是不需要连接的，即刻传输数据2. 服务对象 TCP是点对点连接 UDP支持一对一，一对多，多对多传输3. 可靠性4. 拥塞控制 流量控制5. 首部开销6. 传输方式7. 分片不同TCP和UDP的应用场景 TCP：文件传输 HTTP HTTPSUDP：视频、音频 DNS、SMP（包比较小）","categories":[{"name":"计算机网络","slug":"Network","permalink":"https://songsong.ink/categories/Network/"}],"tags":[]},{"title":"SYN Flood攻击以及解决方法","slug":"SYN-Flood攻击以及解决方法","date":"2021-07-27T13:35:07.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/27/f3207c9d4a24.html","link":"","permalink":"https://songsong.ink/2021/07/27/f3207c9d4a24.html","excerpt":"","text":"SYN Flood攻击以及解决方法_Ther Meng的博客-CSDN博客 Excerptsyn flood攻击最基本的DoS攻击就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。syn flood属于Dos攻击的一种。如果恶意的向某个服务器端口发送大量的SYN包，则可以使服务器打开大量的半开连接，分配TCB（Transmission Control Block）, 从而消耗大量的服务器资源，同时也使得正常的连接请求无法被相应。当开放了一个TCP端口后，… syn flood攻击 最基本的DoS攻击就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。syn flood属于Dos攻击的一种。 如果恶意的向某个服务器端口发送大量的SYN包，则可以使服务器打开大量的半开连接，分配TCB（Transmission Control Block）, 从而消耗大量的服务器资源，同时也使得正常的连接请求无法被相应。当开放了一个TCP端口后，该端口就处于Listening状态，不停地监视发到该端口的Syn报文，一 旦接收到Client发来的Syn报文，就需要为该请求分配一个TCB，通常一个TCB至少需要280个字节，在某些操作系统中TCB甚至需要1300个字节，并返回一个SYN ACK命令，立即转为SYN-RECEIVED即半开连接状态。系统会为此耗尽资源。 常见的防攻击方法有： 无效连接的监视释放 监视系统的半开连接和不活动连接，当达到一定阈值时拆除这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，而且由于SYN Flood造成的半开连接数量很大，正常连接请求也被淹没在其中被这种方式误释放掉，因此这种方法属于入门级的SYN Flood方法。 延缓TCB分配方法 消耗服务器资源主要是因为当SYN数据报文一到达，系统立即分配TCB，从而占用了资源。而SYN Flood由于很难建立起正常连接，因此，当正常连接建立起来后再分配TCB则可以有效地减轻服务器资源的消耗。常见的方法是使用Syn Cache和Syn Cookie技术。 Syn Cache技术 系统在收到一个SYN报文时，在一个专用HASH表中保存这种半连接信息，直到收到正确的回应ACK报文再分配TCB。这个开销远小于TCB的开销。当然还需要保存序列号。 Syn Cookie技术 Syn Cookie技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS(Maximum Segment Size，最大报文段大小，指的是TCP报文的最大数据报长度，其中不包括TCP首部长度。)、时间等，在收到对方 的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源。 使用SYN Proxy防火墙 一种方式是防止墙dqywb连接的有效性后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c, 而真正的服务器回应的序列号为c’, 这样，在每个数据报文经过防火墙的时候进行序列号的修改。另一种方式是防火墙确定了连接的安全后，会发出一个safe reset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。 点个赞，点个收藏，评论下更先显温情！","categories":[],"tags":[]},{"title":"三次握手四次挥手","slug":"三次握手四次挥手","date":"2021-07-27T13:31:17.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/27/33e37655d720.html","link":"","permalink":"https://songsong.ink/2021/07/27/33e37655d720.html","excerpt":"","text":"为什么是三次握手？不是两次、四次？相信大家比较常回答的是：“因为三次握手才能保证双方具有接收和发送的能力。” 这回答是没问题，但这回答是片面的，并没有说出主要的原因。 我们先来知道什么是 TCP 连接？ 用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。 所以，重要的是为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接。 接下来以三个方面分析三次握手的原因： 三次握手才可以阻止重复历史连接的初始化（主要原因） 三次握手才可以同步双方的初始序列号 三次握手才可以避免资源浪费 原因一：避免历史连接 我们来看看 RFC 793 指出的 TCP 连接使用三次握手的首要原因： The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion. 简单来说，三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。 网络环境是错综复杂的，往往并不是如我们期望的一样，先发送的数据包，就先到达目标主机，反而它很骚，可能会由于网络拥堵等乱七八糟的原因，会使得旧的数据包，先到达目标主机，那么这种情况下 TCP 三次握手是如何避免的呢？ 客户端连续发送多次 SYN 建立连接的报文，在网络拥堵等情况下： 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端； 那么此时服务端就会回一个 SYN + ACK 报文给客户端； 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 RST 报文给服务端，表示中止这一次连接。 如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接： 如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 RST 报文，以此中止历史连接； 如果不是历史连接，则第三次发送的报文是 ACK 报文，通信双方就会成功建立连接； 所以， TCP 使用三次握手建立连接的最主要原因是防止历史连接初始化了连接。 原因二：同步双方初始序列号 TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用： 接收方可以去除重复的数据； 接收方可以根据数据包的序列号按序接收； 可以标识发送出去的数据包中， 哪些是已经被对方收到的； 可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。 四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」。 而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。 原因三：避免资源浪费 如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？ 如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。 即两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 SYN 报文，而造成重复分配资源。 TCP 四次挥手 TCP 四次挥手过程和状态变迁 天下没有不散的宴席，对于 TCP 连接也是这样， TCP 断开连接是通过四次挥手方式。 双方都可以主动断开连接，断开连接后主机中的「资源」将被释放。 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务器收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。 你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。 这里一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。 为什么挥手需要四次？再来回顾下四次挥手双方发 FIN 包的过程，就能理解为什么需要四次了。 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。 为什么 TIME_WAIT 等待的时间是 2MSL？ MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。 MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。 TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。 比如如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。 在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。 其定义在 Linux 内核代码里的名称为 TCP_TIMEWAIT_LEN： 12#define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT state, about 60 seconds */ 如果要修改 TIME_WAIT 的时间长度，只能修改 Linux 内核代码里 TCP_TIMEWAIT_LEN 的值，并重新编译 Linux 内核。 为什么需要 TIME_WAIT 状态？ 主动发起关闭连接的一方，才会有 TIME-WAIT 状态。 需要 TIME-WAIT 状态，主要是两个原因： 防止具有相同「四元组」的「旧」数据包被收到； 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭； 原因一：防止旧连接的数据包 假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？ 如上图黄色框框服务端在关闭连接之前发送的 SEQ = 301 报文，被网络延迟了。 这时有相同端口的 TCP 连接被复用后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题。 所以，TCP 就设计出了这么一个机制，经过 2MSL 这个时间，足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。 原因二：保证连接正确关闭 在 RFC 793 指出 TIME-WAIT 另一个重要的作用是： TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request. 也就是说，TIME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。 假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？ 如上图红色框框客户端四次挥手的最后一个 ACK 报文如果在网络中被丢失了，此时如果客户端 TIME-WAIT 过短或没有，则就直接进入了 CLOSE 状态了，那么服务端则会一直处在 LASE-ACK 状态。 当客户端发起建立连接的 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被终止。 如果 TIME-WAIT 等待足够长的情况就会遇到两种情况： 服务端正常收到四次挥手的最后一个 ACK 报文，则服务端正常关闭连接。 服务端没有收到四次挥手的最后一个 ACK 报文时，则会重发 FIN 关闭连接报文并等待新的 ACK 报文。 所以客户端在 TIME-WAIT 状态等待 2MSL 时间后，就可以保证双方的连接都可以正常的关闭。 TIME_WAIT 过多有什么危害？ 如果服务器有处于 TIME-WAIT 状态的 TCP，则说明是由服务器方主动发起的断开请求。 过多的 TIME-WAIT 状态主要的危害有两种： 第一是内存资源占用； 第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口； 第二个危害是会造成严重的后果的，要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过如下参数设置指定 1net.ipv4.ip_local_port_range 如果发起连接一方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。 客户端受端口资源限制： 客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接。 服务端受系统资源限制： 由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，服务端确实只监听一个端口 但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以当服务端出现大量 TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连接。 如何优化 TIME_WAIT？ 这里给出优化 TIME-WAIT 的几个方式，都是有利有弊： 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项； net.ipv4.tcp_max_tw_buckets 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。 方式一：net.ipv4.tcp_tw_reuse 和 tcp_timestamps 如下的 Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。 有一点需要注意的是，tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。 1net.ipv4.tcp_tw_reuse = 1 使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即 1net.ipv4.tcp_timestamps=1（默认即为 1） 这个时间戳的字段是在 TCP 头部的「选项」里，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳。 由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。 方式二：net.ipv4.tcp_max_tw_buckets 这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将所有的 TIME_WAIT 连接状态重置。 这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。 方式三：程序中使用 SO_LINGER 我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。 1234struct linger so_linger;so_linger.l_onoff = 1;so_linger.l_linger = 0;setsockopt(s, SOL_SOCKET, SO_LINGER, &amp;so_linger,sizeof(so_linger)); 如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。 但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。","categories":[{"name":"计算机网络","slug":"Network","permalink":"https://songsong.ink/categories/Network/"}],"tags":[]},{"title":"数据库事务","slug":"数据库事务","date":"2021-07-27T13:10:01.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/27/d92c84f925a5.html","link":"","permalink":"https://songsong.ink/2021/07/27/d92c84f925a5.html","excerpt":"","text":"数据库事务事务概述事务（Transaction）是数据库区别于文件系统的重要特性之一。在文件系统中，如果正在写文件，但是操作系统突然崩溃了，这个文件就很有可能被破坏。当然，有一些机制可以把文件恢复到某个时间点。不过，如果需要保证两个文件同步，这些文件系统可能就显得无能为力了。例如，在需要更新两个文件时，更新完一个文件后，在更新完第二个文件之前系统重启了，就会有两个不同步的文件。 这正是数据库系统引入事务的主要目的：事务会把数据库从一种一致状态转换为另一种一致状态。在数据库提交工作时，可以确保要么所有修改都已经保存了，要么所有修改都不保存。 InnoDB存储引擎中的事务完全符合ACID的特性。ACID是以下4个词的缩写： 原子性（atomicity） 一致性（consistency） 隔离性（isolation） 持久性（durability） 四大特性A（Atomicity），原子性。原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，才算整个事务成功。事务中任何一个SQL语句执行失败，已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。 如果事务中的操作都是只读的，要保持原子性是很简单的。一旦发生任何错误，要么重试，要么返回错误代码。因为只读操作不会改变系统中的任何相关部分。但是，当事务中的操作需要改变系统中的状态时，例如插入记录或更新记录，那么情况可能就不像只读操作那么简单了。如果操作失败，很有可能引起状态的变化，因此必须要保护系统中并发用户访问受影响的部分数据。 C（consistency），一致性一致性指事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。例如，在表中有一个字段为姓名，为唯一约束，即在表中姓名不能重复。如果一个事务对姓名字段进行了修改，但是在事务提交或事务操作发生回滚后，表中的姓名变得非唯一了，这就破坏了事务的一致性要求，即事务将数据库从一种状态变为了一种不一致的状态。因此，事务是一致性的单位，如果事务中某个动作失败了，系统可以自动撤销事务——返回初始化的状态。 I（isolation），隔离性。隔离性还有其他的称呼，如并发控制（concurrency control）、可串行化（serializability）、锁（locking）等。事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，通常这使用锁来实现。当前数据库系统中都提供了一种粒度锁（granular lock）的策略，允许事务仅锁住一个实体对象的子集，以此来提高事务之间的并发度。 D（durability），持久性。事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据库也能将数据恢复。需要注意的是，只能从事务本身的角度来保证结果的永久性。例如，在事务提交后，所有的变化都是永久的。即使当数据库因为崩溃而需要恢复时，也能保证恢复后提交的数据都不会丢失。但若不是数据库本身发生故障，而是一些外部的原因，如RAID卡损坏、自然灾害等原因导致数据库发生问题，那么所有提交的数据可能都会丢失。因此持久性保证事务系统的高可靠性（High Reliability），而不是高可用性（High Availability）。对于高可用性的实现，事务本身并不能保证，需要一些系统共同配合来完成。 事务实现事务隔离性由锁来实现。原子性、一致性、持久性通过数据库的redo log和undo log来完成。redo log称为重做日志，用来保证事务的原子性和持久性。undo log用来保证事务的一致性。有人或许会认为undo是redo的逆过程，其实不然。redo和undo的作用都可以视为是一种恢复操作，redo恢复提交事务修改的页操作，而undo回滚行记录到某个特定版本。因此两者记录的内容不同，redo通常是物理日志，记录的是页的物理修改操作。undo是逻辑日志，根据每行记录进行记录。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://songsong.ink/categories/mysql/"}],"tags":[]},{"title":"7.22work","slug":"7-22work","date":"2021-07-22T15:51:45.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/22/9c9e226f0329.html","link":"","permalink":"https://songsong.ink/2021/07/22/9c9e226f0329.html","excerpt":"","text":"创意title 取物料的第一条图片取视频封面看marketApi的代码 后续视频看是否需要加表","categories":[],"tags":[]},{"title":"垃圾收集","slug":"垃圾收集","date":"2021-07-21T10:25:59.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/21/4249c39389fc.html","link":"","permalink":"https://songsong.ink/2021/07/21/4249c39389fc.html","excerpt":"","text":"对象已死判断引用计数法引用计数法实在对象中添加一个引用计数器，每当有一个地方引用他时，计数器就加一；当引用失效时，计数器减一；任何时刻计数器为0的对象就是不可能在被使用的。 引用计数法回占用一些额外的存储空间来进行计数，但是原理简单，判断效率搞。但是看似简单的算法有很多例外的情况需要考虑，譬如单纯的引用计数法无法解决对象之间循环引用的问题，这就需要大量额外处理才能保证正确地工作。 循环引用问题对象objA 和 objB都有字段instance，令 ，objB.instance = objA。此外两个对象没有其他引用，实际上两个对象已经不可能在被访问，但是他们互选引用着对方，导致他们的引用计数器不为0，引用计数算法无法对他们进行回收。 代码样例 123456789101112131415161718192021222324252627public class ReferenceCountingGC &#123; public Object instance = null; private static final int _1MB = 1024*1024; /** * 这个成员属性的唯一意义就是占点内存，以便能在GC日志中看清楚是否有回收过 */ private byte[] bigSize = new byte[2 * _1MB]; public static void testGC() &#123; ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = new ReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; // 假设在这行发生GC，objA和objB是否能被回收？ System.gc(); &#125; public static void main(String[] args) &#123; testGC(); &#125;&#125; 可达性分析可达性分析（eachability Analysis）的基本思路时通过一系列GC ROOTs 的根对象作为其实节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain）如果这个对象到GC ROOTS没有任何引用链相连，或者说不可达，则证明对象不可能再使用的。 GC ROOTs的对象固定的GC ROOTS集合 虚拟机栈（栈帧中的本地变量表）中引用的对象，比如使用到的参数、局部变量、临时变量等 方法区中类静态属性引用的变量，比如java类的引用类型静态变量 方法区中常量引用的对象，比如字符串常量池（String table）的引用 本地方法栈中JNI（native方法）引用的对象 java虚拟机内部的引用，比如基本数据类型对应的Class对象，常驻异常对象（OutOfMEmoryError NullPointException）等，还有系统类加载器 同步锁持有的对象 java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存 非固定的GC ROOTS根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合。（跨代引用问题） 引用分类引用计数算法和可达性分析都是通过引用来判断对象是否存活。一个对象只有“引用”和“引用未”这两种状态在有些情况下不能完全适用。比如缓存这种对象，当内存空间还足够时，能够保留在内存中，如果内存空间进行垃圾收集后仍然非常紧张，那就可以抛弃这些对象。 JDK1.2后引用的概念进行了扩充引用的分类有 强引用 Object obj=new Object() 这种引用关系。无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象。 软引用 描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2版之后提供了SoftReference类来实现软引用。 弱引用 描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2版之后提供了WeakReference类来实现弱引用。 虚引用 也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。在JDK 1.2版之后提供了PhantomReference类来实现虚引用。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://songsong.ink/categories/jvm/"}],"tags":[{"name":"垃圾收集算法","slug":"GC","permalink":"https://songsong.ink/tags/GC/"},{"name":"对象死亡判断","slug":"对象死亡判断","permalink":"https://songsong.ink/tags/%E5%AF%B9%E8%B1%A1%E6%AD%BB%E4%BA%A1%E5%88%A4%E6%96%AD/"}]},{"title":"5815. 扣分后的最大得分","slug":"5815-扣分后的最大得分","date":"2021-07-20T18:05:19.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/20/d4c3b12b93ea.html","link":"","permalink":"https://songsong.ink/2021/07/20/d4c3b12b93ea.html","excerpt":"","text":"扣分后的最大得分题目给你一个 m x n 的整数矩阵 points （下标从 0 开始）。一开始你的得分为 0 ，你想最大化从矩阵中得到的分数。 你的得分方式为：每一行 中选取一个格子，选中坐标为 (r, c) 的格子会给你的总得分 增加 points[r][c] 。 然而，相邻行之间被选中的格子如果隔得太远，你会失去一些得分。对于相邻行 r 和 r + 1 （其中 0 &lt;= r &lt; m - 1），选中坐标为 (r, c1) 和 (r + 1, c2) 的格子，你的总得分 减少 abs(c1 - c2) 。 请你返回你能得到的 最大 得分。 abs(x) 定义为： 如果 x &gt;= 0 ，那么值为 x 。 如果 x &lt; 0 ，那么值为 -x 。 思路 回溯 动态规划 动态规划优化 选择问题一般都可以用回溯的思路进行解决，但是回溯的时间复杂度很大。 1234567891011121314151617181920class Solution &#123; int res = 0; public long maxPoints(int[][] points) &#123; dfs(points,0,0,0); return res; &#125; public void dfs(int[][] points,int row, int col, int score)&#123; if (row &gt;= points.length) &#123; res = Math.max(res,score); return; &#125; for (int i = 0; i &lt; points[row].length; i++) &#123; int newScore = score + points[row][i]; if (row &gt; 0)&#123; newScore -= Math.abs(col - i); &#125; dfs(points,row+1,i,newScore); &#125; &#125;&#125; 动态规划解法dp[i][j] 代表i行j列的最大得分 状态转移方程：dp[i][j] = max{ dp[i-1][k] + points[i][j] + abs(j-k) ,k = 0-n n为points列长度}时间复杂度？ 123456789101112131415161718192021222324252627282930class Solution &#123; public long maxPoints(int[][] points) &#123; if (points.length == 0) &#123; return 0; &#125; long result = 0; int m = points.length; int n = points[0].length; long[][] dp = new long[m][n]; for (int i = 0; i &lt; n; i++) &#123; dp[0][i] = points[0][i]; result = Math.max(result,dp[0][i]); &#125; for (int i = 1; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; for (int k = 0; k &lt; n; k++) &#123; long score = points[i][j] + dp[i-1][k] - Math.abs(j-k); dp[i][j] = Math.max(score,dp[i][j]); &#125; result = Math.max(result,dp[i][j]); &#125; &#125; return result; &#125; &#125; 动态规划优化解法 12","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://songsong.ink/categories/leetcode/"}],"tags":[{"name":"周赛","slug":"周赛","permalink":"https://songsong.ink/tags/%E5%91%A8%E8%B5%9B/"},{"name":"面试","slug":"面试","permalink":"https://songsong.ink/tags/%E9%9D%A2%E8%AF%95/"},{"name":"中等","slug":"中等","permalink":"https://songsong.ink/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"msyql事务隔离级别与锁机制","slug":"mysql事务隔离级别与锁机制","date":"2021-07-20T18:05:19.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/20/a064a04de36f.html","link":"","permalink":"https://songsong.ink/2021/07/20/a064a04de36f.html","excerpt":"","text":"概述我们的数据库一般都会并发执行多个事务，多个事务可能会并发的对相同的一批数据进行增删改查操作，可能就会导致我们说的脏写、脏读、不可重复读、幻读这些问题。这些问题的本质都是数据库的多事务并发问题，为了解决多事务并发问题，数据库设计了事务隔离机制、锁机制、MVCC多版本并发控制隔离机制，用一整套机制来解决多事务并发问题。接下来，我们会深入讲解这些机制，让大家彻底理解数据库内部的执行原理。 事务及其ACID属性事务是由一组SQL语句组成的逻辑处理单元,事务具有以下4个属性,通常简称为事务的ACID属性。 原子性(Atomicity) ：事务是一个原子操作单元,其对数据的修改,要么全都执行,要么全都不执行。 一致性(Consistent) ：在事务开始和完成时,数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改,以保持数据的完整性。 隔离性(Isolation) ：数据库系统提供一定的隔离机制,保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的,反之亦然。 持久性(Durable) ：事务完成之后,它对于数据的修改是永久性的,即使出现系统故障也能够保持。 并发事务处理带来的问题1. 更新丢失(Lost Update)或脏写 当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题–最后的更新覆盖了由其他事务所做的更新。 2. 脏读（Dirty Reads） 一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致的状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此作进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象的叫做“脏读”。 一句话：事务A读取到了事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。 3. 不可重读（Non-Repeatable Reads） 一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。 一句话：事务A内部的相同查询语句在不同时刻读出的结果不一致，不符合隔离性 4. 幻读（Phantom Reads） 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 一句话：事务A读取到了事务B提交的新增数据，不符合隔离性 事务隔离级别“脏读”、“不可重复读”和“幻读”,其实都是数据库读一致性问题,必须由数据库提供一定的事务隔离机制来解决。 数据库的事务隔离越严格,并发副作用越小,但付出的代价也就越大,因为事务隔离实质上就是使事务在一定程度上“串行化”进行,这显然与“并发”是矛盾的。同时,不同的应用对读一致性和事务隔离程度的要求也是不同的,比如许多应用对“不可重复读”和“幻读”并不敏感,可能更关心数据并发访问的能力。常看当前数据库的事务隔离级别: show variables like ‘tx_isolation’;设置事务隔离级别：set tx_isolation=’REPEATABLE-READ’;Mysql默认的事务隔离级别是可重复读，用Spring开发程序时，如果不设置隔离级别默认用Mysql设置的隔离级别，如果Spring设置了就用已经设置的隔离级别 锁详解锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除了传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供需要用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。 锁分类 从性能上分为乐观锁(用版本对比来实现)和悲观锁 从对数据库操作的类型分，分为读锁和写锁(都属于悲观锁) 读锁（共享锁，S锁(Shared)）：针对同一份数据，多个读操作可以同时进行而不会互相影响 写锁（排它锁，X锁(eXclusive)）：当前写操作没有完成前，它会阻断其他写锁和读锁 从对数据操作的粒度分，分为表锁和行锁 表锁每次操作锁住整张表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；一般用在整表数据迁移的场景。行锁实际上是对主键索引加锁开销大基本操作 123456789101112--建表SQLCREATE TABLE `mylock` ( `id` INT (11) NOT NULL AUTO_INCREMENT, `NAME` VARCHAR (20) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE = MyISAM DEFAULT CHARSET = utf8;--插入数据INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;1&#x27;, &#x27;a&#x27;);INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;2&#x27;, &#x27;b&#x27;);INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;3&#x27;, &#x27;c&#x27;);INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;4&#x27;, &#x27;d&#x27;); 手动增加表锁 1lock table 表名称 read(write),表名称2 read(write); 查看表上加过的锁 1show open tables; 删除表锁 1unlock tables; 案例分析(加读锁） 当前session和其他session都可以读该表当前session中插入或者更新锁定的表都会报错，其他session插入或更新则会等待 案例分析(加写锁） 当前session对该表的增删改查都没有问题，其他session对该表的所有操作被阻塞 案例结论1、对MyISAM表的读操作(加读锁) ,不会阻塞其他进程对同一表的读请求,但会阻塞对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。2、对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作 行锁每次操作锁住一行数据。开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度最高。InnoDB与MYISAM的最大不同有两点：InnoDB支持事务（TRANSACTION）InnoDB支持行级锁 行锁演示一个session开启事务更新不提交，另一个session更新同一条记录会阻塞，更新不同记录不会阻塞 总结：MyISAM在执行查询语句SELECT前，会自动给涉及的所有表加读锁,在执行update、insert、delete操作会自动给涉及的表加写锁。InnoDB在执行查询语句SELECT时(非串行隔离级别)，不会加锁。但是update、insert、delete操作会加行锁。简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。 行锁与事务隔离级别案例分析123456789CREATE TABLE `account` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `balance` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `test`.`account` (`name`, `balance`) VALUES (&#x27;lilei&#x27;, &#x27;450&#x27;);INSERT INTO `test`.`account` (`name`, `balance`) VALUES (&#x27;hanmei&#x27;, &#x27;16000&#x27;);INSERT INTO `test`.`account` (`name`, `balance`) VALUES (&#x27;lucy&#x27;, &#x27;2400&#x27;); 读未提交：（1）打开一个客户端A，并设置当前事务模式为read uncommitted（未提交读），查询表account的初始值： 1234# MySQL8查询事务应该使用transaction_isolation，tx_isolation在MySQL 5.7.20后被弃用。set tx_isolation=&#x27;read-uncommitted&#x27;;-- 8.0set transaction_isolation=&#x27;read-uncommitted&#x27;; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： （3）这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据： （4）一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据： （5）在客户端A执行更新语句update account set balance = balance - 50 where id =1，lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别 3、读已提交（1）打开一个客户端A，并设置当前事务模式为read committed（未提交读），查询表account的所有记录：set tx_isolation=’read-committed’; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： （3）这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题： （4）客户端B的事务提交 （5）客户端A执行与上一步相同的查询，结果 与上一步不一致，即产生了不可重复读的问题 4、可重复读（1）打开一个客户端A，并设置当前事务模式为repeatable read，查询表account的所有记录set tx_isolation=’repeatable-read’; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交 （3）在客户端A查询表account的所有记录，与步骤（1）查询结果一致，没有出现不可重复读的问题 （4）在客户端A，接着执行update account set balance = balance - 50 where id = 1，balance没有变成400-50=350，lilei的balance值用的是步骤2中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC(multi-version concurrency control)机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。 （5）重新打开客户端B，插入一条新数据后提交 （6）在客户端A查询表account的所有记录，没有查出新增数据，所以没有出现幻读 （7)验证幻读在客户端A执行update account set balance=888 where id = 4;能更新成功，再次查询能查到客户端B新增的数据 5、串行化（1）打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值：set tx_isolation=’serializable’; （2）打开一个客户端B，并设置当前事务模式为serializable，更新相同的id为1的记录会被阻塞等待，更新id为2的记录可以成功，说明在串行模式下innodb的查询也会被加上行锁。如果客户端A执行的是一个范围查询，那么该范围内的所有行包括每行记录所在的间隙区间范围(就算该行数据还未被插入也会加锁，这种是间隙锁)都会被加锁。此时如果客户端B在该范围内插入数据都会被阻塞，所以就避免了幻读。这种隔离级别并发性极低，开发中很少会用到。 间隙锁(Gap Lock)间隙锁，锁的就是两个值之间的空隙。Mysql默认级别是repeatable-read，有办法解决幻读问题吗？间隙锁在某些情况下可以解决幻读问题。假设account表里数据如下： 那么间隙就有 id 为 (3,10)，(10,20)，(20,正无穷) 这三个区间，在Session_1下面执行 update account set name = ‘zhuge’ where id &gt; 8 and id &lt;18;，则其他Session没法在这个范围所包含的所有行记录(包括间隙行记录)以及行记录所在的间隙里插入或修改任何数据，即id在(3,20]区间都无法修改数据，注意最后那个20也是包含在内的。间隙锁是在可重复读隔离级别下才会生效。 临键锁(Next-key Locks)Next-Key Locks是行锁与间隙锁的组合。像上面那个例子里的这个(3,20]的整个区间可以叫做临键锁。 无索引行锁会升级为表锁(RR级别会升级为表锁，RC级别不会升级为表锁)锁主要是加在索引上，如果对非索引字段更新，行锁可能会变表锁session1 执行：update account set balance = 800 where name = ‘lilei’;session2 对该表任一行操作都会阻塞住InnoDB的行锁是针对索引加的锁，不是针对记录加的锁。并且该索引不能失效，否则都会从行锁升级为表锁。 锁定某一行还可以用lock in share mode(共享锁) 和for update(排它锁)，例如：select * from test_innodb_lock where a = 2 for update; 这样其他session只能读这行数据，修改则会被阻塞，直到锁定行的session提交 结论Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更高一下，但是在整体并发处理能力方面要远远优于MYISAM的表级锁定的。当系统并发量高的时候，Innodb的整体性能和MYISAM相比就会有比较明显的优势了。但是，Innodb的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让Innodb的整体性能表现不仅不能比MYISAM高，甚至可能会更差。 行锁分析通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况show status like ‘innodb_row_lock%’; 对各个状态量的说明如下：Innodb_row_lock_current_waits: 当前正在等待锁定的数量Innodb_row_lock_time: 从系统启动到现在锁定总时间长度Innodb_row_lock_time_avg: 每次等待所花平均时间Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间Innodb_row_lock_waits: 系统启动后到现在总共等待的次数 对于这5个状态变量，比较重要的主要是：Innodb_row_lock_time_avg （等待平均时长）Innodb_row_lock_waits （等待总次数）Innodb_row_lock_time（等待总时长） 尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。 查看INFORMATION_SCHEMA系统库锁相关数据表– 查看事务select * from INFORMATION_SCHEMA.INNODB_TRX;– 查看锁select * from INFORMATION_SCHEMA.INNODB_LOCKS;– 查看锁等待select * from INFORMATION_SCHEMA.INNODB_LOCK_WAITS; – 释放锁，trx_mysql_thread_id可以从INNODB_TRX表里查看到kill trx_mysql_thread_id – 查看锁等待详细信息show engine innodb status\\G; 死锁set tx_isolation=’repeatable-read’;Session_1执行：select * from account where id=1 for update;Session_2执行：select * from account where id=2 for update;Session_1执行：select * from account where id=2 for update;Session_2执行：select * from account where id=1 for update;查看近期死锁日志信息：show engine innodb status\\G;大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁 锁优化建议尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁合理设计索引，尽量缩小锁的范围尽可能减少检索条件范围，避免间隙锁尽量控制事务大小，减少锁定资源量和时间长度，涉及事务加锁的sql尽量放在事务最后执行尽可能低级别事务隔离","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://songsong.ink/tags/mysql/"}]},{"title":"mysql缓冲池","slug":"mysql缓冲池","date":"2021-07-20T18:05:19.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/20/3b09f9fb9d8b.html","link":"","permalink":"https://songsong.ink/2021/07/20/3b09f9fb9d8b.html","excerpt":"","text":"","categories":[{"name":"mysql","slug":"mysql","permalink":"https://songsong.ink/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://songsong.ink/tags/mysql/"},{"name":"缓冲池","slug":"缓冲池","permalink":"https://songsong.ink/tags/%E7%BC%93%E5%86%B2%E6%B1%A0/"}]},{"title":"JVM基础故障处理工具","slug":"JVM基础故障处理工具","date":"2021-07-19T13:51:53.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/19/97193fbf6df9.html","link":"","permalink":"https://songsong.ink/2021/07/19/97193fbf6df9.html","excerpt":"","text":"基础故障处理工具1.jdk小工具命名方式JDK的很多小工具的名字都参考了UNIX命令的命名方式。 2.jps（JVM Process Status Tool）jps是虚拟机进程状况工具。jps名字和UNIX的ps命令类似，它的功能也和ps命令类似： 可以列出正在运行的虚拟机进程， 显示虚拟机执行主类（Main Class，main()函数所在的类）名称 以及这些进程的本地虚拟机唯一ID（LVMID，Local Virtual Machine Identifier）。 2.1jps命令格式1jps [options] [hostid] 参数 描述 -q 只输出LVMID，省略主类的名称 -m 输出虚拟机进程启动时传递给主类main（）函数的参数 -l 输出主类的全名，如果进程执行的是jar包，则输出JAR路径 -v 输出虚拟机进程启动时的JVM参数 jps还可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，参数hostid为RMI注册表中注册的主机名。 2.2jps执行样例1234567jps -l4672 sun.tools.jps.Jps7364 org.jetbrains.jps.cmdline.Launcher24440 C:/Program28808 org.jetbrains.jps.cmdline.Launcher5128 3.jstat (JVM Statistics Monitoring Tool )jstat是jdk自带的虚拟机统计信息监视工具。用于监视虚拟机各种运行状态信息的工具。它可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾手机、即时编译等运行时数据，在只提供了控制台的服务器上，它将是在软件运行期间定位虚拟机性能问题的常用工具。 3.1命令格式1jstat [option vmid interval[s|ms] [count]] ] 对于命令格式中的VMID与LVMID需要特别说明一下：如果是本地虚拟机进程，VMID与LVMID是一致的；如果是远程虚拟机进程，那VMID的格式应当是： 1[protocol:][//]lvmid[@hostname[:port]/servername] 参数interval和count代表查询间隔和次数，如果省略这2个参数，说明只查询一次。假设需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是：jstat -gc 2764 250 20选项option代表用户希望查询的虚拟机信息，主要分为三类：类加载、垃圾收集、运行期编译状况。详细请参考表4-2中的描述。 选项 作用 -class 监视类加载、卸载数量、总空间以及类加载所消耗的时间 -gc 监视java堆情况，包括Eden区、survivor区、老年代、永久代等的容量，已用空间，垃圾收集时间合计等信息 -gccapacity 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间 -gcutil 监视内容与-gc基本相同，但输出主要关注以使用空间占总空间的百分比 -gccause 监视内容与-gcutil功能一样，但是会额外输出导致上一次垃圾收集产生的原因 -gcnew 监视新生代垃圾收集状况 -gcnewcapacity 监视内容与-gc基本相同，但输出主要关注使用到的最大、最小空间 -gcold 监视老年代垃圾收集状况 -gcoldcapacity 监视内容与-gcold基本相同，但输出主要关注使用到的最大、最小空间 -gcmetacapacity 输出元空间使用到的最大、最小空间 -compiler 输出即时编译器编译过的方法，耗时等信息 -printcompilation 输出已经被即时编译的方法 缩写 描述 S0C 第一个幸存区的大小 S1C 第二个幸存区的大小 S0U 第一个幸存区的使用大小 S1U 第二个幸存区的使用大小 EC 伊甸园区的大小 EU 伊甸园区的使用大小 OC 老年代大小 OU 老年代使用大小 MC 方法区大小(元空间) MU 方法区使用大小 CCSC 压缩类空间大小 CCSU CCSU:压缩类空间使用大小 YGC 年轻代垃圾回收次数 YGCT 年轻代垃圾回收消耗时间，单位s FGC 老年代垃圾回收次数 FGCT 老年代垃圾回收消耗时间，单位s GCT 垃圾回收消耗总时间，单位s 3.jinfo Java配置信息工具4.jmap java内存映像工具5.jhat 虚拟机堆转储快照分析工具6.jstack Java堆栈跟踪工具基础工具总结","categories":[{"name":"jvm","slug":"jvm","permalink":"https://songsong.ink/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://songsong.ink/tags/jvm/"},{"name":"基础故障","slug":"基础故障","permalink":"https://songsong.ink/tags/%E5%9F%BA%E7%A1%80%E6%95%85%E9%9A%9C/"}]},{"title":"面试题 10.02. 变位词组","slug":"新的文章","date":"2021-07-17T22:48:34.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/17/63f05b595936.html","link":"","permalink":"https://songsong.ink/2021/07/17/63f05b595936.html","excerpt":"","text":"面试题 10.02. 变位词组题目描述编写一种方法，对字符串数组进行排序，将所有变位词组合在一起。变位词是指字母相同，但排列不同的字符串。 示例: 1234567输入: [&quot;eat&quot;, &quot;tea&quot;, &quot;tan&quot;, &quot;ate&quot;, &quot;nat&quot;, &quot;bat&quot;],输出:[ [&quot;ate&quot;,&quot;eat&quot;,&quot;tea&quot;], [&quot;nat&quot;,&quot;tan&quot;], [&quot;bat&quot;]] 说明： 所有输入均为小写字母。 不考虑答案输出的顺序。 题解一问题分解 如何识别字符串是同一个变位词？ 同一个变位词如何快速加入到对应的数组中？ 思路：对于第一个问题： 对将变位词进行计数排序，返回排序好的字符串，将返回的字符串作为哈希表的key， 123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.ArrayList;import java.util.HashMap;import java.util;class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; List&lt;List&lt;String&gt;&gt; result = new ArrayList(); HashMap&lt;String ,List&lt;String&gt;&gt; map = new HashMap(); for ( String str: strs) &#123; String key = count(str); List&lt;String&gt; list; if (!map.containsKey(key)) &#123; list = new ArrayList&lt;String&gt;(); result.add(list); map.put(key,list); &#125;else &#123; list = map.get(key); &#125; list.add(str); &#125; return result; &#125; public String count(String str) &#123; int[] bit = new int[26]; for (int i = 0; i &lt; str.length(); i++) &#123; char c = str.charAt(i); bit[c -&#x27;a&#x27;] ++; &#125; StringBuilder stringBuilder = new StringBuilder(); for (int i = 0; i &lt; 26; i++) &#123; char c = (char)(&#x27;a&#x27; + i); for (int j = 0; j &lt; bit[i]; j++) &#123; stringBuilder.append(c); &#125; &#125; return stringBuilder.toString(); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://songsong.ink/categories/leetcode/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://songsong.ink/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"leetcode","slug":"leetcode","permalink":"https://songsong.ink/tags/leetcode/"},{"name":"每日一题","slug":"每日一题","permalink":"https://songsong.ink/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/"}]},{"title":"mysql索引","slug":"mysql索引","date":"2021-07-15T11:38:47.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/15/d148b73a7a10.html","link":"","permalink":"https://songsong.ink/2021/07/15/d148b73a7a10.html","excerpt":"","text":"mysql索引索引是什么索引是帮助Mysql高效获取数据的排好序的数据结构。 索引可以用的数据结构有： 二叉树 红黑树 Hash表 B-Tree BTree 叶子节点具有相同的深度，叶节点的指针为空 所有索引元素不重复 节点中的数据索引从左往右递增排列 B+树（B树变种） 非叶子节点不存储data，只存储索引（索引会冗余），因此每页可以存储更多索引 叶子节点包含所有索引字段 叶子节点用指针连接，提高区间访问能力 聚集索引索引文件和数据文件在一起的是聚集索引。 非聚集索引索引文件和数据文件分离的是非聚集索引 InnoDB索引实现InnoDb索引是聚集索引。表数据本身就是按照B+树结构存储的一个索引结构文件。因此InnDB存储的表必须存在主键。辅助索引使用的非聚集索引。存储的是主键值。聚集索引的叶子节点包含了完整的数据记录。 为何InonoDB非主键索引结构叶子节点存储的是主键值非主键索引叶子节点存储主键而不是存储数据是从两方面考虑。一是如果存储数据数据的更新删除添加操作会存在数据不一致问题。维护数据一致性会很复杂。二是会浪费大量空间。 为什么InnoDb表必须有主键且推荐使用整型的自增主键表数据本身就是按照B+树结构存储的，因此必须有主键， 联合索引联合索引的存储结构也是采用b+树，索引值是按照构建索引时键的顺序存储。叶子节点存储的是主键值。 最左前缀原理如果要使用联合索引必须要遵循最左前缀原理使用。比如key（a,b,c）直接使用c是几乎不会走索引的。也就是说要使用联合索引的字段进行查询。在联合索引中这个字段的左侧字段也必须使用。不然不会走索引（覆盖索引例外）。 覆盖索引","categories":[{"name":"数据库","slug":"DataBase","permalink":"https://songsong.ink/categories/DataBase/"}],"tags":[{"name":"数据库","slug":"database","permalink":"https://songsong.ink/tags/database/"},{"name":"索引","slug":"索引","permalink":"https://songsong.ink/tags/%E7%B4%A2%E5%BC%95/"},{"name":"数据结构","slug":"数据结构","permalink":"https://songsong.ink/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"B+树","slug":"B-树","permalink":"https://songsong.ink/tags/B-%E6%A0%91/"},{"name":"Hash","slug":"Hash","permalink":"https://songsong.ink/tags/Hash/"}]},{"title":"三大范式","slug":"三大范式","date":"2021-07-15T11:33:24.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/15/6600b3cedb94.html","link":"","permalink":"https://songsong.ink/2021/07/15/6600b3cedb94.html","excerpt":"","text":"三大范式第一范式（1NF）：要求数据库表的每一列都是不可分割的原子数据项。 第二范式（2NF）：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖） 第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。 第三范式（3NF）：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖） 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。","categories":[{"name":"数据库","slug":"DataBase","permalink":"https://songsong.ink/categories/DataBase/"}],"tags":[{"name":"数据库","slug":"database","permalink":"https://songsong.ink/tags/database/"},{"name":"范式","slug":"范式","permalink":"https://songsong.ink/tags/%E8%8C%83%E5%BC%8F/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-07-14T20:18:04.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/14/e02fd06e5bfc.html","link":"","permalink":"https://songsong.ink/2021/07/14/e02fd06e5bfc.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing jnimgdemo 1234567&#123;% qnimg test/demo.jpg title:图片标题 alt:图片说明 &#x27;class:class1 class2&#x27; %&#125;&#123;% qnimg imageFile attr1:value1 attr2:value2 &#x27;attr3:value31 value32 value3n&#x27; [extend:?imageView2/2/w/600 | normal:yes] %&#125;&#123;% qnjs jsFile attr1:value1 attr2:value2 &#x27;attr3:value31 value32 value3n&#x27; %&#125;&#123;% qncss cssFile attr1:value1 attr2:value2 &#x27;attr3:value31 value32 value3n&#x27; %&#125; Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 1$ hexo","categories":[],"tags":[]},{"title":"原型模式","slug":"原型模式","date":"2021-07-14T20:18:04.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/14/bfe50c9d7eb1.html","link":"","permalink":"https://songsong.ink/2021/07/14/bfe50c9d7eb1.html","excerpt":"","text":"原型模式(Prototype)知识点 Cloneable接口/Object#clone方法 详解 浅拷贝/深拷贝 序列化机制实现深拷贝 模式定义:指原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 应用场景：当代码不应该依赖于需要复制的对象的具体类时，请使用Prototype模式。 优点： 可以不耦合具体类的情况下克隆对象 避免重复的初始化代码 更方便的构建复杂对象 Spring源码中的应用 org.springframework.beans.factory.support.bstractBeanDefinition java.util.Arrays","categories":[{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/categories/DesignPattern/"}],"tags":[{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/tags/DesignPattern/"},{"name":"原型模式","slug":"原型模式","permalink":"https://songsong.ink/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"Prototype","slug":"Prototype","permalink":"https://songsong.ink/tags/Prototype/"},{"name":"浅拷贝","slug":"浅拷贝","permalink":"https://songsong.ink/tags/%E6%B5%85%E6%8B%B7%E8%B4%9D/"},{"name":"深拷贝","slug":"深拷贝","permalink":"https://songsong.ink/tags/%E6%B7%B1%E6%8B%B7%E8%B4%9D/"}]},{"title":"观察者模式","slug":"观察者模式","date":"2021-07-14T20:07:30.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/14/5bfd545d12b3.html","link":"","permalink":"https://songsong.ink/2021/07/14/5bfd545d12b3.html","excerpt":"","text":"观察者模式(Observer)模式定义定义了对象之间的一对多依赖，让多个观察者对象同时监听某一个主题 对象，当主题对象发生变化时，它的所有依赖者都会收到通知并更新。 应用场景当更改一个对象的状态可能需要更改其他对象，并且实际的对象集事先 未知或动态更改时，请使用观察者模式。 优点 符合开闭原则 可以在运行时建立对象之间的关系 jdk&amp;源码中的应用 JDK: java.util.Observable Spring: org.springframework.context.ApplicationListener","categories":[{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/categories/DesignPattern/"}],"tags":[{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/tags/DesignPattern/"},{"name":"观察者模式","slug":"观察者模式","permalink":"https://songsong.ink/tags/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"name":"Observer","slug":"Observer","permalink":"https://songsong.ink/tags/Observer/"}]},{"title":"模板方法模式","slug":"模板方法模式","date":"2021-07-14T19:51:04.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/14/cd123a041e29.html","link":"","permalink":"https://songsong.ink/2021/07/14/cd123a041e29.html","excerpt":"","text":"模板方法(Template Method)模式定义定义一个操作的算法骨架，而将一些步骤延迟到子类中。Template Method 使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤 样例代码1234567891011121314151617181920212223242526public class TemplateMethodTest &#123; public static void main(String[] args) &#123; AbstractClass abstractClass = new SubClass(); abstractClass.operation(); &#125;&#125;abstract class AbstractClass&#123; public void operation() &#123; // 定义一个操作的算法骨架 System.out.println(&quot; step 1&quot;); System.out.println(&quot; step 2&quot;); System.out.println(&quot; step 3&quot;); //步骤延迟 templateMethod(); &#125; protected abstract void templateMethod();&#125;class SubClass extends AbstractClass &#123; @Override protected void templateMethod() &#123; System.out.println(&quot;subclass step&quot;); &#125;&#125; 应用场景 当你想让客户端只扩展算法的特定步骤，而不是整个算法或其结构 时，请使用Template Method模式。 当你有几个类包含几乎相同的算法，但有一些细微的差异时，请使用 此模式。 优点： 你可以让客户端只覆盖大型算法的某些部分，从而减少算法其他部分发生的更改对它们的影响。 你可以将重复的代码拖放到超类中。 实际应用 javax.servlet.http.HttpServlet org.springframework.web.servlet.mvc.AbstractController","categories":[{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/categories/DesignPattern/"}],"tags":[{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/tags/DesignPattern/"},{"name":"模板方法","slug":"模板方法","permalink":"https://songsong.ink/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/"}]},{"title":"单例模式","slug":"单例模式","date":"2021-07-14T18:48:33.000Z","updated":"2022-05-15T08:41:27.453Z","comments":true,"path":"2021/07/14/052711817fb7.html","link":"","permalink":"https://songsong.ink/2021/07/14/052711817fb7.html","excerpt":"","text":"单例设计模式（Singleton）知识点 模式定义/应用场景/类图分析 字节码知识/字节码指令重排序 类加载机制 JVM序列化机制 单例模式在Spring框架 &amp; JDK源码中的应用 模式定义保证一个类只有一个实例，并且提供一个全局的访问点 使用场景重量级对象。不需要单个实例，如线程池，数据库连接池 实现方式1.懒汉模式懒汉模式：延迟加载， 只有在真正使用的时候，才开始实例化。 存在问题： 线程安全问题 double check 加锁优化 编译器(JIT),CPU 有可能对指令进行重排序，导致使用到尚未初始化 的实例，可以通过添加volatile 关键字进行修饰， 对于volatile 修饰的字段，可以防止指令重排。（具体原理后续文章展开） 1234567891011121314151617181920212223242526class LazySingleton&#123; private volatile static LazySingleton instance; private LazySingleton()&#123; &#125; public static LazySingleton getInstance() &#123; if (instance==null)&#123; synchronized (LazySingleton.class)&#123; if (instance==null)&#123; instance=new LazySingleton(); // 字节码层 // JIT ， CPU 有可能对如下指令进行重排序 // 1 .分配空间 // 2 .初始化 // 3 .引用赋值 // 如重排序后的结果为如下 // 1 .分配空间 // 3 .引用赋值 如果在当前指令执行完，有其他线程来获取实例，将拿到尚未初始化好的实例 // 2 .初始化 &#125; &#125; &#125; return instance; &#125;&#125; 2.饿汉模式：类加载的初始化阶段就完成了实例的初始化。本质上就是借助于jvm 类加载机制，保证实例的唯一性（初始化过程只会执行一次）及线程安全（JVM以同步的形式来完成类加载的整个过程）。 类加载过程： 加载二进制数据到内存中， 生成对应的Class数据结构， 连接： a. 验证， b.准备（给类的静态成员变量赋默认值），c.解析 初始化： 给类的静态变量赋初值 只有在真正使用对应的类时，才会触发初始化 如（ 当前类是启动类即 main函数所在类，直接进行new 操作，访问静态属性、访问静态方法，用反射访问类，初始化一个类的子类等.） 123456789// 饿汉模式 class HungrySingleton&#123; private static HungrySingleton instance=new HungrySingleton(); private HungrySingleton()&#123; &#125; public static HungrySingleton getInstance() &#123; return instance; &#125;&#125; 3.静态内部类 本质上是利用类的加载机制来保证线程安全 只有在实际使用的时候，才会触发类的初始化，所以也是懒加载的一 种形式。123456789class InnerClassSingleton&#123; private static class InnerClassHolder&#123; private static InnerClassSingleton instance= new InnerClassSingleton(); &#125; private InnerClassSingleton()&#123; &#125; public static InnerClassSingleton getInstance()&#123; return InnerClassHolder.instance; &#125;&#125;","categories":[{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/categories/DesignPattern/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"https://songsong.ink/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/tags/DesignPattern/"},{"name":"懒加载","slug":"懒加载","permalink":"https://songsong.ink/tags/%E6%87%92%E5%8A%A0%E8%BD%BD/"}]}],"categories":[{"name":"git","slug":"git","permalink":"https://songsong.ink/categories/git/"},{"name":"vps","slug":"vps","permalink":"https://songsong.ink/categories/vps/"},{"name":"linux-commond","slug":"linux-commond","permalink":"https://songsong.ink/categories/linux-commond/"},{"name":"win10","slug":"win10","permalink":"https://songsong.ink/categories/win10/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"https://songsong.ink/categories/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"},{"name":"cache","slug":"cache","permalink":"https://songsong.ink/categories/cache/"},{"name":"RPC","slug":"RPC","permalink":"https://songsong.ink/categories/RPC/"},{"name":"面试题","slug":"面试题","permalink":"https://songsong.ink/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://songsong.ink/categories/rabbitmq/"},{"name":"计算机网络","slug":"Network","permalink":"https://songsong.ink/categories/Network/"},{"name":"nginx","slug":"nginx","permalink":"https://songsong.ink/categories/nginx/"},{"name":"spring","slug":"spring","permalink":"https://songsong.ink/categories/spring/"},{"name":"redis","slug":"redis","permalink":"https://songsong.ink/categories/redis/"},{"name":"linux","slug":"linux","permalink":"https://songsong.ink/categories/linux/"},{"name":"进程","slug":"进程","permalink":"https://songsong.ink/categories/%E8%BF%9B%E7%A8%8B/"},{"name":"HTTP","slug":"HTTP","permalink":"https://songsong.ink/categories/HTTP/"},{"name":"springboot","slug":"springboot","permalink":"https://songsong.ink/categories/springboot/"},{"name":"idea","slug":"idea","permalink":"https://songsong.ink/categories/idea/"},{"name":"企业微信接入","slug":"企业微信接入","permalink":"https://songsong.ink/categories/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%8E%A5%E5%85%A5/"},{"name":"缓存","slug":"cache","permalink":"https://songsong.ink/categories/cache/"},{"name":"面试汇总","slug":"面试汇总","permalink":"https://songsong.ink/categories/%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/"},{"name":"mysql","slug":"mysql","permalink":"https://songsong.ink/categories/mysql/"},{"name":"jvm","slug":"jvm","permalink":"https://songsong.ink/categories/jvm/"},{"name":"leetcode","slug":"leetcode","permalink":"https://songsong.ink/categories/leetcode/"},{"name":"数据库","slug":"DataBase","permalink":"https://songsong.ink/categories/DataBase/"},{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/categories/DesignPattern/"}],"tags":[{"name":"git","slug":"git","permalink":"https://songsong.ink/tags/git/"},{"name":"vps","slug":"vps","permalink":"https://songsong.ink/tags/vps/"},{"name":"linux","slug":"linux","permalink":"https://songsong.ink/tags/linux/"},{"name":"commond-line","slug":"commond-line","permalink":"https://songsong.ink/tags/commond-line/"},{"name":"打印服务","slug":"打印服务","permalink":"https://songsong.ink/tags/%E6%89%93%E5%8D%B0%E6%9C%8D%E5%8A%A1/"},{"name":"cache","slug":"cache","permalink":"https://songsong.ink/tags/cache/"},{"name":"零拷贝","slug":"零拷贝","permalink":"https://songsong.ink/tags/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"},{"name":"review","slug":"review","permalink":"https://songsong.ink/tags/review/"},{"name":"nginx","slug":"nginx","permalink":"https://songsong.ink/tags/nginx/"},{"name":"ubuntu hostname","slug":"ubuntu-hostname","permalink":"https://songsong.ink/tags/ubuntu-hostname/"},{"name":"HTTP.1","slug":"HTTP-1","permalink":"https://songsong.ink/tags/HTTP-1/"},{"name":"缓存","slug":"缓存","permalink":"https://songsong.ink/tags/%E7%BC%93%E5%AD%98/"},{"name":"垃圾收集算法","slug":"GC","permalink":"https://songsong.ink/tags/GC/"},{"name":"对象死亡判断","slug":"对象死亡判断","permalink":"https://songsong.ink/tags/%E5%AF%B9%E8%B1%A1%E6%AD%BB%E4%BA%A1%E5%88%A4%E6%96%AD/"},{"name":"周赛","slug":"周赛","permalink":"https://songsong.ink/tags/%E5%91%A8%E8%B5%9B/"},{"name":"面试","slug":"面试","permalink":"https://songsong.ink/tags/%E9%9D%A2%E8%AF%95/"},{"name":"中等","slug":"中等","permalink":"https://songsong.ink/tags/%E4%B8%AD%E7%AD%89/"},{"name":"mysql","slug":"mysql","permalink":"https://songsong.ink/tags/mysql/"},{"name":"缓冲池","slug":"缓冲池","permalink":"https://songsong.ink/tags/%E7%BC%93%E5%86%B2%E6%B1%A0/"},{"name":"jvm","slug":"jvm","permalink":"https://songsong.ink/tags/jvm/"},{"name":"基础故障","slug":"基础故障","permalink":"https://songsong.ink/tags/%E5%9F%BA%E7%A1%80%E6%95%85%E9%9A%9C/"},{"name":"面试题","slug":"面试题","permalink":"https://songsong.ink/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"leetcode","slug":"leetcode","permalink":"https://songsong.ink/tags/leetcode/"},{"name":"每日一题","slug":"每日一题","permalink":"https://songsong.ink/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/"},{"name":"数据库","slug":"database","permalink":"https://songsong.ink/tags/database/"},{"name":"索引","slug":"索引","permalink":"https://songsong.ink/tags/%E7%B4%A2%E5%BC%95/"},{"name":"数据结构","slug":"数据结构","permalink":"https://songsong.ink/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"B+树","slug":"B-树","permalink":"https://songsong.ink/tags/B-%E6%A0%91/"},{"name":"Hash","slug":"Hash","permalink":"https://songsong.ink/tags/Hash/"},{"name":"范式","slug":"范式","permalink":"https://songsong.ink/tags/%E8%8C%83%E5%BC%8F/"},{"name":"设计模式","slug":"DesignPattern","permalink":"https://songsong.ink/tags/DesignPattern/"},{"name":"原型模式","slug":"原型模式","permalink":"https://songsong.ink/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"Prototype","slug":"Prototype","permalink":"https://songsong.ink/tags/Prototype/"},{"name":"浅拷贝","slug":"浅拷贝","permalink":"https://songsong.ink/tags/%E6%B5%85%E6%8B%B7%E8%B4%9D/"},{"name":"深拷贝","slug":"深拷贝","permalink":"https://songsong.ink/tags/%E6%B7%B1%E6%8B%B7%E8%B4%9D/"},{"name":"观察者模式","slug":"观察者模式","permalink":"https://songsong.ink/tags/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"name":"Observer","slug":"Observer","permalink":"https://songsong.ink/tags/Observer/"},{"name":"模板方法","slug":"模板方法","permalink":"https://songsong.ink/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/"},{"name":"单例模式","slug":"单例模式","permalink":"https://songsong.ink/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"懒加载","slug":"懒加载","permalink":"https://songsong.ink/tags/%E6%87%92%E5%8A%A0%E8%BD%BD/"}]}